{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACD_CNN_Glove_SemEval2014.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXqeuOhS8yff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "13df985d-8cad-4230-e967-4eafd421210b"
      },
      "source": [
        "pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9sUuB5S84wu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "outputId": "e49bcfae-20f5-4a50-997e-1546e15e4126"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==1.15.0 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.30.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (49.2.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0y-jIsq5fMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8c5b1210-411e-4748-a7e7-ab497a3076b7"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/Aspect Category Detection/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cSTIi6c56tn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "42d6f624-0e06-4bab-acec-9de05dec7a76"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import layers\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET, getopt, logging, sys, random, re, copy, os\n",
        "from lxml import etree\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_L0p9Fm58XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getSentences(file):\n",
        "  tree = ET.parse(file, etree.XMLParser(recover=True, encoding=\"utf-8\"))\n",
        "  root = tree.getroot()\n",
        "  s = []\n",
        "  p = []\n",
        "  #for review in root.findall('Review'):\n",
        "  for sentence in root.findall('sentence'):\n",
        "    #for sentence in sentences.findall('sentence'):\n",
        "    sent = []\n",
        "    sent_characteristics = []\n",
        "    text = sentence.find('text').text\n",
        "    sent.append(text)\n",
        "    polarity = []\n",
        "    for opinions in sentence.findall('aspectCategories'):\n",
        "      for opinion in opinions.findall('aspectCategory'):\n",
        "        elem = [opinion.get('category'), opinion.get('polarity')]\n",
        "        polarity.append(elem)\n",
        "    sent_characteristics.append(polarity)\n",
        "    s.append(sent)\n",
        "    p.append(sent_characteristics)\n",
        "        \n",
        "  return s, p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMX17gHa6Wif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences, train_adnotations = getSentences(\"./SemEval2014_train.xml\")\n",
        "test_sentences, test_adnotations = getSentences(\"./SemEval2014_test.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7GkgPaj6eEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_reviews = []\n",
        "train_aspects = []\n",
        "test_reviews = []\n",
        "test_aspects = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UymnLR_6iB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in train_sentences:\n",
        "  train_reviews.append(' '.join(review))\n",
        "for ta in train_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  train_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8VLNear6kMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in test_sentences:\n",
        "  test_reviews.append(' '.join(review))\n",
        "  \n",
        "for ta in test_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  test_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DUR-Gln6mLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLabels(aspects):\n",
        "\t#print(unique_aspects)\n",
        "\t#Create train labels\n",
        "  food = []\n",
        "  service\t= []\n",
        "  miscellaneous = []\n",
        "  ambience = []\n",
        "  price = []\n",
        "\n",
        "  for aspect in aspects:\n",
        "    if 'food' in aspect:\n",
        "      food.append(1)\n",
        "    else:\n",
        "      food.append(0)\n",
        "\t\t\t\n",
        "    if 'anecdotes/miscellaneous' in aspect:\n",
        "      miscellaneous.append(1)\n",
        "    else:\n",
        "      miscellaneous.append(0)\n",
        "\t\t\t\n",
        "    if 'service' in aspect:\n",
        "      service.append(1)\n",
        "    else:\n",
        "      service.append(0)\n",
        "\n",
        "    if 'ambience' in aspect:\n",
        "      ambience.append(1)\n",
        "    else:\n",
        "      ambience.append(0)\n",
        "\t\t\t  \n",
        "    if 'price' in aspect:\n",
        "      price.append(1)\n",
        "    else:\n",
        "      price.append(0)\n",
        "\t\t\t\t\n",
        "  return food, miscellaneous ,service ,price , ambience"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCOInmGG6qO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test and Train labels\n",
        "test1, test2, test3, test4, test5 = getLabels(test_aspects)\n",
        "test_labels = [test1, test2, test3, test4, test5]\n",
        "\n",
        "train1, train2, train3, train4, train5 = getLabels(train_aspects)\n",
        "train_labels = [train1, train2, train3, train4, train5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ttwM81t6274",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3cdf235a-7953-46ec-855f-e943591da8b6"
      },
      "source": [
        "#Vectorizing data\n",
        "vectorizer = CountVectorizer(analyzer='word', lowercase=True, stop_words='english', ngram_range=(1,2))\n",
        "vectorizer.fit(train_reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onMqGUqe66Ze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = vectorizer.transform(train_reviews)\n",
        "x_test = vectorizer.transform(test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPKY1Gfj69G1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[1]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(train_reviews)\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(train_reviews)\n",
        "x_test = tokenizer.texts_to_sequences(test_reviews)\n",
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3If407IF7HY1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 100\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding = 'post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO6ExcTk7KTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pretrained Word Embeddings\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "\tvocab_size = len(word_index) + 1\n",
        "\tembedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\t\n",
        "\twith open(filepath, encoding='utf-8') as f:\n",
        "\t\tfor line in f:\n",
        "\t\t\tword, *vector = line.split()\n",
        "\t\t\tif word in word_index:\n",
        "\t\t\t\tidx = word_index[word]\n",
        "\t\t\t\tembedding_matrix[idx] = np.array(vector[-300:], dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "\treturn embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoyXlrhL7Ocz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = create_embedding_matrix('./glove.840B.300d.txt', tokenizer.word_index, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKtqas8m7X3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "def getPredictions(x_train, x_test, train, test):\n",
        "\tembedding_dim = 300\n",
        "\t#early_stopping_monitor = EarlyStopping(patience=3)\n",
        "\tembedding_matrix = create_embedding_matrix('./glove.840B.300d.txt', tokenizer.word_index, embedding_dim)\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length = maxlen, trainable = True))\n",
        "\tmodel.add(layers.Conv1D(64, 3, activation = 'relu'))\n",
        "\tmodel.add(layers.GlobalMaxPool1D())\n",
        "\tmodel.add(layers.Dense(10, activation='relu'))\n",
        "\tmodel.add(layers.Dense(1, activation='sigmoid'))\n",
        "\tmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1, 'accuracy'])\n",
        "\t#model.summary()\n",
        "\n",
        "\thistory = model.fit(x_train, train, epochs = 15, verbose = 1, validation_data = (x_test, test), batch_size = 10)\n",
        "\tval = model.evaluate(x_train, train, verbose = False)\n",
        "\tval = model.evaluate(x_test, test, verbose = False)\n",
        "\n",
        "\tpredictions = model.predict(x_test)\n",
        "\tpredictions_class = model.predict_classes(x_test)\n",
        "\t#predictions1 = model.predict(testt)\n",
        "\t#predictions11 = model.predict_classes(testt)\n",
        "\treturn predictions, predictions_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji7oMYqb7_4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        Only computes a batch-wise average of recall.\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "        Only computes a batch-wise average of precision.\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sJTyMLN8I7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a014e2ec-e15b-4096-97bb-ed917b1099ce"
      },
      "source": [
        "print(\"Getting Predictions1\")\n",
        "predictions1, predictions_class1 = getPredictions(x_train, x_test, train1, test1)\n",
        "print(\"Getting Predictions2\")\n",
        "predictions2, predictions_class2 = getPredictions(x_train, x_test, train2, test2)\n",
        "print(\"Getting Predictions3\")\n",
        "predictions3, predictions_class3 = getPredictions(x_train, x_test, train3, test3)\n",
        "print(\"Getting Predictions4\")\n",
        "predictions4, predictions_class4 = getPredictions(x_train, x_test, train4, test4)\n",
        "print(\"Getting Predictions5\")\n",
        "predictions5, predictions_class5 = getPredictions(x_train, x_test, train5, test5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Predictions1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3041/3041 [==============================] - 11s 4ms/step - loss: 0.2959 - f1: 0.8156 - acc: 0.8767 - val_loss: 0.2177 - val_f1: 0.9116 - val_acc: 0.9212\n",
            "Epoch 2/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.1336 - f1: 0.9333 - acc: 0.9520 - val_loss: 0.2181 - val_f1: 0.9139 - val_acc: 0.9237\n",
            "Epoch 3/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0518 - f1: 0.9807 - acc: 0.9865 - val_loss: 0.2384 - val_f1: 0.9140 - val_acc: 0.9237\n",
            "Epoch 4/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0178 - f1: 0.9948 - acc: 0.9964 - val_loss: 0.2701 - val_f1: 0.9170 - val_acc: 0.9262\n",
            "Epoch 5/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0056 - f1: 0.9892 - acc: 0.9993 - val_loss: 0.2986 - val_f1: 0.9016 - val_acc: 0.9112\n",
            "Epoch 6/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0016 - f1: 0.9997 - acc: 1.0000 - val_loss: 0.3130 - val_f1: 0.9080 - val_acc: 0.9187\n",
            "Epoch 7/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 7.3490e-04 - f1: 0.9964 - acc: 1.0000 - val_loss: 0.3276 - val_f1: 0.9091 - val_acc: 0.9200\n",
            "Epoch 8/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 4.2689e-04 - f1: 0.9931 - acc: 1.0000 - val_loss: 0.3446 - val_f1: 0.9091 - val_acc: 0.9200\n",
            "Epoch 9/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 2.6761e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3558 - val_f1: 0.9105 - val_acc: 0.9212\n",
            "Epoch 10/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.8769e-04 - f1: 0.9964 - acc: 1.0000 - val_loss: 0.3699 - val_f1: 0.9091 - val_acc: 0.9200\n",
            "Epoch 11/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.3446e-04 - f1: 0.9931 - acc: 1.0000 - val_loss: 0.3855 - val_f1: 0.9077 - val_acc: 0.9187\n",
            "Epoch 12/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 9.8663e-05 - f1: 0.9964 - acc: 1.0000 - val_loss: 0.3901 - val_f1: 0.9091 - val_acc: 0.9200\n",
            "Epoch 13/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 7.4453e-05 - f1: 0.9901 - acc: 1.0000 - val_loss: 0.4003 - val_f1: 0.9080 - val_acc: 0.9187\n",
            "Epoch 14/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 5.6809e-05 - f1: 0.9964 - acc: 1.0000 - val_loss: 0.4107 - val_f1: 0.9080 - val_acc: 0.9187\n",
            "Epoch 15/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 4.3833e-05 - f1: 0.9934 - acc: 1.0000 - val_loss: 0.4188 - val_f1: 0.9080 - val_acc: 0.9187\n",
            "Getting Predictions2\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3041/3041 [==============================] - 11s 3ms/step - loss: 0.4018 - f1: 0.6742 - acc: 0.8020 - val_loss: 0.3484 - val_f1: 0.7007 - val_acc: 0.8487\n",
            "Epoch 2/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.2159 - f1: 0.8557 - acc: 0.9152 - val_loss: 0.3508 - val_f1: 0.6969 - val_acc: 0.8675\n",
            "Epoch 3/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.1086 - f1: 0.9410 - acc: 0.9635 - val_loss: 0.3998 - val_f1: 0.6485 - val_acc: 0.8650\n",
            "Epoch 4/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0272 - f1: 0.9787 - acc: 0.9954 - val_loss: 0.5176 - val_f1: 0.6626 - val_acc: 0.8637\n",
            "Epoch 5/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0079 - f1: 0.9868 - acc: 1.0000 - val_loss: 0.5022 - val_f1: 0.6966 - val_acc: 0.8625\n",
            "Epoch 6/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0030 - f1: 0.9964 - acc: 1.0000 - val_loss: 0.5543 - val_f1: 0.6930 - val_acc: 0.8675\n",
            "Epoch 7/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0015 - f1: 0.9901 - acc: 1.0000 - val_loss: 0.5799 - val_f1: 0.6935 - val_acc: 0.8675\n",
            "Epoch 8/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 9.8995e-04 - f1: 0.9967 - acc: 1.0000 - val_loss: 0.5962 - val_f1: 0.6969 - val_acc: 0.8712\n",
            "Epoch 9/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 6.8963e-04 - f1: 0.9898 - acc: 1.0000 - val_loss: 0.6152 - val_f1: 0.6948 - val_acc: 0.8700\n",
            "Epoch 10/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 4.9487e-04 - f1: 0.9868 - acc: 1.0000 - val_loss: 0.6439 - val_f1: 0.6958 - val_acc: 0.8700\n",
            "Epoch 11/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 3.6717e-04 - f1: 0.9934 - acc: 1.0000 - val_loss: 0.6585 - val_f1: 0.6937 - val_acc: 0.8687\n",
            "Epoch 12/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 2.7887e-04 - f1: 0.9865 - acc: 1.0000 - val_loss: 0.6788 - val_f1: 0.6934 - val_acc: 0.8687\n",
            "Epoch 13/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 2.1445e-04 - f1: 0.9934 - acc: 1.0000 - val_loss: 0.6975 - val_f1: 0.6934 - val_acc: 0.8687\n",
            "Epoch 14/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.6790e-04 - f1: 0.9934 - acc: 1.0000 - val_loss: 0.7165 - val_f1: 0.6934 - val_acc: 0.8687\n",
            "Epoch 15/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.3202e-04 - f1: 0.9865 - acc: 1.0000 - val_loss: 0.7348 - val_f1: 0.6934 - val_acc: 0.8687\n",
            "Getting Predictions3\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.2521 - f1: 0.5486 - acc: 0.9112 - val_loss: 0.1235 - val_f1: 0.7482 - val_acc: 0.9575\n",
            "Epoch 2/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 0.0816 - f1: 0.8058 - acc: 0.9724 - val_loss: 0.1338 - val_f1: 0.7912 - val_acc: 0.9575\n",
            "Epoch 3/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 0.0288 - f1: 0.8507 - acc: 0.9941 - val_loss: 0.1283 - val_f1: 0.7528 - val_acc: 0.9525\n",
            "Epoch 4/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 0.0063 - f1: 0.8861 - acc: 0.9993 - val_loss: 0.1438 - val_f1: 0.7409 - val_acc: 0.9487\n",
            "Epoch 5/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 0.0013 - f1: 0.8714 - acc: 1.0000 - val_loss: 0.1572 - val_f1: 0.7516 - val_acc: 0.9512\n",
            "Epoch 6/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 5.1112e-04 - f1: 0.8813 - acc: 1.0000 - val_loss: 0.1691 - val_f1: 0.7509 - val_acc: 0.9512\n",
            "Epoch 7/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 2.6129e-04 - f1: 0.9244 - acc: 1.0000 - val_loss: 0.1809 - val_f1: 0.7491 - val_acc: 0.9500\n",
            "Epoch 8/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.5517e-04 - f1: 0.8813 - acc: 1.0000 - val_loss: 0.1874 - val_f1: 0.7509 - val_acc: 0.9512\n",
            "Epoch 9/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 1.0049e-04 - f1: 0.8912 - acc: 1.0000 - val_loss: 0.1898 - val_f1: 0.7509 - val_acc: 0.9512\n",
            "Epoch 10/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 6.8867e-05 - f1: 0.8846 - acc: 1.0000 - val_loss: 0.2033 - val_f1: 0.7509 - val_acc: 0.9512\n",
            "Epoch 11/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 4.9155e-05 - f1: 0.8879 - acc: 1.0000 - val_loss: 0.2132 - val_f1: 0.7439 - val_acc: 0.9487\n",
            "Epoch 12/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 3.6811e-05 - f1: 0.8879 - acc: 1.0000 - val_loss: 0.2151 - val_f1: 0.7522 - val_acc: 0.9525\n",
            "Epoch 13/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 2.7691e-05 - f1: 0.8846 - acc: 1.0000 - val_loss: 0.2159 - val_f1: 0.7550 - val_acc: 0.9525\n",
            "Epoch 14/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 2.1377e-05 - f1: 0.8944 - acc: 1.0000 - val_loss: 0.2290 - val_f1: 0.7463 - val_acc: 0.9500\n",
            "Epoch 15/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.6740e-05 - f1: 0.8912 - acc: 1.0000 - val_loss: 0.2258 - val_f1: 0.7550 - val_acc: 0.9525\n",
            "Getting Predictions4\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.1845 - f1: 0.3654 - acc: 0.9395 - val_loss: 0.0817 - val_f1: 0.4668 - val_acc: 0.9700\n",
            "Epoch 2/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0584 - f1: 0.6221 - acc: 0.9796 - val_loss: 0.0721 - val_f1: 0.4821 - val_acc: 0.9737\n",
            "Epoch 3/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0194 - f1: 0.6563 - acc: 0.9941 - val_loss: 0.0613 - val_f1: 0.5147 - val_acc: 0.9825\n",
            "Epoch 4/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0061 - f1: 0.6796 - acc: 0.9987 - val_loss: 0.0745 - val_f1: 0.4903 - val_acc: 0.9762\n",
            "Epoch 5/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0022 - f1: 0.6807 - acc: 1.0000 - val_loss: 0.0852 - val_f1: 0.4735 - val_acc: 0.9737\n",
            "Epoch 6/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0013 - f1: 0.6741 - acc: 0.9997 - val_loss: 0.0873 - val_f1: 0.4735 - val_acc: 0.9737\n",
            "Epoch 7/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 5.6059e-04 - f1: 0.6610 - acc: 1.0000 - val_loss: 0.0949 - val_f1: 0.4860 - val_acc: 0.9750\n",
            "Epoch 8/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 3.7133e-04 - f1: 0.6643 - acc: 1.0000 - val_loss: 0.0950 - val_f1: 0.4717 - val_acc: 0.9725\n",
            "Epoch 9/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 2.3450e-04 - f1: 0.6577 - acc: 1.0000 - val_loss: 0.0902 - val_f1: 0.4947 - val_acc: 0.9775\n",
            "Epoch 10/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.7218e-04 - f1: 0.6939 - acc: 1.0000 - val_loss: 0.0979 - val_f1: 0.4717 - val_acc: 0.9725\n",
            "Epoch 11/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.3080e-04 - f1: 0.6347 - acc: 1.0000 - val_loss: 0.0992 - val_f1: 0.4842 - val_acc: 0.9737\n",
            "Epoch 12/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 9.9891e-05 - f1: 0.6873 - acc: 1.0000 - val_loss: 0.0972 - val_f1: 0.4906 - val_acc: 0.9762\n",
            "Epoch 13/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 7.8402e-05 - f1: 0.7070 - acc: 1.0000 - val_loss: 0.1041 - val_f1: 0.4739 - val_acc: 0.9737\n",
            "Epoch 14/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 6.1373e-05 - f1: 0.6643 - acc: 1.0000 - val_loss: 0.1080 - val_f1: 0.4781 - val_acc: 0.9750\n",
            "Epoch 15/15\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 4.8905e-05 - f1: 0.6906 - acc: 1.0000 - val_loss: 0.1107 - val_f1: 0.4717 - val_acc: 0.9725\n",
            "Getting Predictions5\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.2506 - f1: 0.3273 - acc: 0.9076 - val_loss: 0.1731 - val_f1: 0.5308 - val_acc: 0.9425\n",
            "Epoch 2/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0985 - f1: 0.6657 - acc: 0.9661 - val_loss: 0.1797 - val_f1: 0.5301 - val_acc: 0.9462\n",
            "Epoch 3/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0330 - f1: 0.7520 - acc: 0.9905 - val_loss: 0.1868 - val_f1: 0.5209 - val_acc: 0.9350\n",
            "Epoch 4/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0091 - f1: 0.7648 - acc: 0.9990 - val_loss: 0.2260 - val_f1: 0.5311 - val_acc: 0.9400\n",
            "Epoch 5/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0034 - f1: 0.7655 - acc: 0.9993 - val_loss: 0.3116 - val_f1: 0.5201 - val_acc: 0.9425\n",
            "Epoch 6/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 0.0012 - f1: 0.7764 - acc: 1.0000 - val_loss: 0.2652 - val_f1: 0.5327 - val_acc: 0.9387\n",
            "Epoch 7/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 6.0076e-04 - f1: 0.7826 - acc: 1.0000 - val_loss: 0.2827 - val_f1: 0.5262 - val_acc: 0.9375\n",
            "Epoch 8/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 3.9139e-04 - f1: 0.7662 - acc: 1.0000 - val_loss: 0.3004 - val_f1: 0.5323 - val_acc: 0.9400\n",
            "Epoch 9/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 2.8153e-04 - f1: 0.7695 - acc: 1.0000 - val_loss: 0.3073 - val_f1: 0.5323 - val_acc: 0.9400\n",
            "Epoch 10/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 2.0917e-04 - f1: 0.7761 - acc: 1.0000 - val_loss: 0.3183 - val_f1: 0.5323 - val_acc: 0.9400\n",
            "Epoch 11/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.5975e-04 - f1: 0.7925 - acc: 1.0000 - val_loss: 0.3272 - val_f1: 0.5323 - val_acc: 0.9400\n",
            "Epoch 12/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 1.2495e-04 - f1: 0.7961 - acc: 1.0000 - val_loss: 0.3288 - val_f1: 0.5324 - val_acc: 0.9387\n",
            "Epoch 13/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 9.8482e-05 - f1: 0.7958 - acc: 1.0000 - val_loss: 0.3401 - val_f1: 0.5306 - val_acc: 0.9387\n",
            "Epoch 14/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 7.8758e-05 - f1: 0.7731 - acc: 1.0000 - val_loss: 0.3420 - val_f1: 0.5324 - val_acc: 0.9387\n",
            "Epoch 15/15\n",
            "3041/3041 [==============================] - 10s 3ms/step - loss: 6.3478e-05 - f1: 0.7501 - acc: 1.0000 - val_loss: 0.3516 - val_f1: 0.5306 - val_acc: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDAJM2P59qiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions1 = predictions1[:, 0]\n",
        "predictions_class1 = predictions_class1[:, 0]\n",
        "\n",
        "predictions2 = predictions2[:, 0]\n",
        "predictions_class2 = predictions_class2[:, 0]\n",
        "\n",
        "predictions3 = predictions3[:, 0]\n",
        "predictions_class3 = predictions_class3[:, 0]\n",
        "\n",
        "predictions4 = predictions4[:, 0]\n",
        "predictions_class4 = predictions_class4[:, 0]\n",
        "\n",
        "predictions5 = predictions5[:, 0]\n",
        "predictions_class5 = predictions_class5[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKZ0XfQm9sxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt7nPUZe9unX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b42a760-4b43-4654-b9cb-bcd3cdc919fb"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy1 = accuracy_score(test1, predictions_class1)\n",
        "accuracy2 = accuracy_score(test2, predictions_class2)\n",
        "accuracy3 = accuracy_score(test3, predictions_class3)\n",
        "accuracy4 = accuracy_score(test4, predictions_class4)\n",
        "accuracy5 = accuracy_score(test5, predictions_class5)\n",
        "final_accuracy = (accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy5) / 5\n",
        "final_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3cL6UmB9xV7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7310040a-a5b2-4a96-f9b8-cc63209d2a54"
      },
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision1 = precision_score(test1, predictions_class1)\n",
        "precision2 = precision_score(test2, predictions_class2)\n",
        "precision3 = precision_score(test3, predictions_class3)\n",
        "precision4 = precision_score(test4, predictions_class4)\n",
        "precision5 = precision_score(test5, predictions_class5)\n",
        "final_precision_score = (precision1 + precision2 + precision3 + precision4 + precision5) / 5\n",
        "final_precision_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8887172009837887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTmSx_CO9zmJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6628a07-c49f-4023-bff0-d7ff1750dbec"
      },
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall1 = recall_score(test1, predictions_class1)\n",
        "recall2 = recall_score(test2, predictions_class2)\n",
        "recall3 = recall_score(test3, predictions_class3)\n",
        "recall4 = recall_score(test4, predictions_class4)\n",
        "recall5 = recall_score(test5, predictions_class5)\n",
        "final_recall_score = (recall1 + recall2 + recall3 + recall4 + recall5) / 5\n",
        "final_recall_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7971113958373912"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE28VEL-9123",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10fcd045-c6ad-4457-f1e4-aacb9a54b2aa"
      },
      "source": [
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1_score1 = f1_score(test1, predictions_class1)\n",
        "f1_score2 = f1_score(test2, predictions_class2)\n",
        "f1_score3 = f1_score(test3, predictions_class3)\n",
        "f1_score4 = f1_score(test4, predictions_class4)\n",
        "f1_score5 = f1_score(test5, predictions_class5)\n",
        "final_f1_score = (f1_score1 + f1_score2 + f1_score3 + f1_score4 + f1_score5) / 5\n",
        "final_f1_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8397925296698304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W1g3DMH94bE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e7e7655-d53b-451c-8676-8837bf3aa865"
      },
      "source": [
        "# ROC AUC\n",
        "auc1 = roc_auc_score(test1, predictions_class1)\n",
        "auc2 = roc_auc_score(test2, predictions_class2)\n",
        "auc3 = roc_auc_score(test3, predictions_class3)\n",
        "auc4 = roc_auc_score(test4, predictions_class4)\n",
        "auc5 = roc_auc_score(test5, predictions_class5)\n",
        "final_auc = (auc1 + auc2 + auc3 + auc4 + auc5) / 5\n",
        "final_auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8796566466776721"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}