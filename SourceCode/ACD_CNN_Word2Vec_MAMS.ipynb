{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACD_CNN_Word2Vec_MAMS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "imJ1LZYREcR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "342d8b2c-e2f2-47d0-b3df-d6fbacfbc379"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/Aspect Category Detection/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOrsH7kv0-qo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2fabb104-3a5a-4aa9-c009-0217c26d1678"
      },
      "source": [
        "pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1K5IF7A2Y3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 991
        },
        "outputId": "e44c455d-4366-4a36-cc84-f07719f94434"
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.2.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 31.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.30.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (3.12.4)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (0.8.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (49.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=19d2d7948cb04a2a80ef36e303607d9f53eaab3a5c48d76af49362f3ab5148e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorboard<3,>=2.3.0, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.3.0 has requirement tensorflow-estimator<2.4.0,>=2.3.0, but you'll have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, gast, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxavKmk4Er1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef1e5b13-9d7b-4a55-a0e5-cab5b5d81f54"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import layers\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET, getopt, logging, sys, random, re, copy, os\n",
        "from lxml import etree\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mmeGWYNEtkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getSentences(file):\n",
        "  tree = ET.parse(file, etree.XMLParser(recover=True, encoding=\"utf-8\"))\n",
        "  root = tree.getroot()\n",
        "  s = []\n",
        "  p = []\n",
        "  #for review in root.findall('Review'):\n",
        "  for sentence in root.findall('sentence'):\n",
        "    #for sentence in sentences.findall('sentence'):\n",
        "    sent = []\n",
        "    sent_characteristics = []\n",
        "    text = sentence.find('text').text\n",
        "    sent.append(text)\n",
        "    polarity = []\n",
        "    for opinions in sentence.findall('aspectCategories'):\n",
        "      for opinion in opinions.findall('aspectCategory'):\n",
        "        elem = [opinion.get('category'), opinion.get('polarity')]\n",
        "        polarity.append(elem)\n",
        "    sent_characteristics.append(polarity)\n",
        "    s.append(sent)\n",
        "    p.append(sent_characteristics)\n",
        "        \n",
        "  return s, p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQHa2fx4Ezsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences, train_adnotations = getSentences(\"./MAMS_train.xml\")\n",
        "test_sentences, test_adnotations = getSentences(\"./MAMS_test.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU07xJD0Fbjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "985a072a-ce68-4d9b-f88e-e50be014c4a4"
      },
      "source": [
        "train_sentences[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"It might be the best sit down food I've had in the area, so if you are going to the upright citizen brigade, or the garden, it could be just the place for you.\"],\n",
              " ['Hostess was extremely accommodating when we arrived an hour early for our reservation.'],\n",
              " [\"We were a couple of minutes late for our reservation and minus one guest, but we didn't think we deserved the attitude we got from the hostess.\"],\n",
              " ['Though the service might be a little slow, the waitresses are very friendly.'],\n",
              " ['Although we arrived at the restaurant 10 min late, the hostess did not have a table for us.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZqDhg7HFcuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "94bcae5e-c89f-497d-9d3d-342fcc7b6a7d"
      },
      "source": [
        "train_adnotations [0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[['food', 'positive'], ['place', 'neutral']]],\n",
              " [[['staff', 'positive'], ['miscellaneous', 'neutral']]],\n",
              " [[['miscellaneous', 'neutral'], ['staff', 'negative']]],\n",
              " [[['service', 'negative'], ['staff', 'positive']]],\n",
              " [[['staff', 'negative'], ['miscellaneous', 'neutral']]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNH_dyQ5FfYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_reviews = []\n",
        "train_aspects = []\n",
        "test_reviews = []\n",
        "test_aspects = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRYraZF2FjZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in train_sentences:\n",
        "  train_reviews.append(' '.join(review))\n",
        "for ta in train_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  train_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjRvUey3FlCV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in test_sentences:\n",
        "  test_reviews.append(' '.join(review))\n",
        "  \n",
        "for ta in test_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  test_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDRAYctXFq2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLabels(aspects):\n",
        "\t#print(unique_aspects)\n",
        "\t#Create train labels\n",
        "\tfood = []\n",
        "\tplace = []\n",
        "\tstaff = []\n",
        "\tmiscellaneous = []\n",
        "\tservice\t= []\n",
        "\tmenu = []\n",
        "\tambience = []\n",
        "\tprice = []\n",
        "\n",
        "\tfor aspect in aspects:\n",
        "\t\tif 'food' in aspect:\n",
        "\t\t\tfood.append(1)\n",
        "\t\telse:\n",
        "\t\t\tfood.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'place' in aspect:\n",
        "\t\t\tplace.append(1)\n",
        "\t\telse:\n",
        "\t\t\tplace.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'staff' in aspect:\n",
        "\t\t\tstaff.append(1)\n",
        "\t\telse:\n",
        "\t\t\tstaff.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'miscellaneous' in aspect:\n",
        "\t\t\tmiscellaneous.append(1)\n",
        "\t\telse:\n",
        "\t\t\tmiscellaneous.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'service' in aspect:\n",
        "\t\t\tservice.append(1)\n",
        "\t\telse:\n",
        "\t\t\tservice.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'menu' in aspect:\n",
        "\t\t\tmenu.append(1)\n",
        "\t\telse:\n",
        "\t\t\tmenu.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'ambience' in aspect:\n",
        "\t\t\tambience.append(1)\n",
        "\t\telse:\n",
        "\t\t\tambience.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'price' in aspect:\n",
        "\t\t\tprice.append(1)\n",
        "\t\telse:\n",
        "\t\t\tprice.append(0)\n",
        "\t\t\t\t\n",
        "\treturn food, place ,staff , miscellaneous ,service ,price ,menu , ambience"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAksNZWCFsD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train and test labels\n",
        "train1, train2, train3, train4, train5, train6, train7, train8 = getLabels(train_aspects)\n",
        "train_labels = [train1, train2, train3, train4, train5, train6, train7, train8]\n",
        "\n",
        "test1, test2, test3, test4, test5, test6, test7, test8 = getLabels(test_aspects)\n",
        "test_labels = [test1, test2, test3, test4, test5, test6, test7, test8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yg8lDcsF06-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1f1a6e19-6db3-4ac4-81cb-3651694e2d23"
      },
      "source": [
        "#Vectorizing data\n",
        "vectorizer = CountVectorizer(analyzer='word', lowercase=True, stop_words='english', ngram_range=(1,2))\n",
        "vectorizer.fit(train_reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5bFcxJ2F-RU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = vectorizer.transform(train_reviews)\n",
        "x_test = vectorizer.transform(test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whQZuzShGA-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[1]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(train_reviews)\n",
        "x_train = tokenizer.texts_to_sequences(train_reviews)\n",
        "x_test = tokenizer.texts_to_sequences(test_reviews)\n",
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVo3ZwuhGGLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 100\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding = 'post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IC2iKAGGJPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "ab6712b0-83d0-46f8-aedc-ae8e0f558667"
      },
      "source": [
        "embedding_dim = 300\n",
        "from gensim.models import KeyedVectors\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(os.path.join('./GoogleNews-vectors-negative300.bin.gz'), binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4nWx6_yGMhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "85ed19d9-1984-44fb-ccb3-e8767aa75675"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model: \n",
        "        embedding_vector = word2vec_model[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=maxlen,\n",
        "                            trainable=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkT9cRbAH_4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        Only computes a batch-wise average of recall.\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "        Only computes a batch-wise average of precision.\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzjmdFDGHWpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "def getPredictions(x_train, x_test, train, test):\n",
        "\tembedding_dim = 300\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(embedding_layer)\n",
        "\tmodel.add(layers.Conv1D(64, 3, activation = 'relu'))\n",
        "\tmodel.add(layers.GlobalMaxPool1D())\n",
        "\tmodel.add(layers.Dense(10, activation='relu'))\n",
        "\tmodel.add(layers.Dense(1, activation='sigmoid'))\n",
        "\tmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1, 'accuracy'])\n",
        "\n",
        "\thistory = model.fit(x_train, train, epochs = 15, verbose = 1, validation_data = (x_test, test), batch_size = 10)\n",
        "\tval = model.evaluate(x_train, train, verbose = False)\n",
        "\n",
        "\tpredictions = model.predict(x_test)\n",
        "\tpredictions_class = model.predict_classes(x_test)\n",
        "\n",
        "\treturn predictions, predictions_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhzkRlKOHomr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "636a8b69-4091-4053-ab91-11d4df6ae7fb"
      },
      "source": [
        "print(\"Getting Predictions1\")\n",
        "predictions1, predictions_class1 = getPredictions(x_train, x_test, train1, test1)\n",
        "print(\"Getting Predictions2\")\n",
        "predictions2, predictions_class2 = getPredictions(x_train, x_test, train2, test2)\n",
        "print(\"Getting Predictions3\")\n",
        "predictions3, predictions_class3 = getPredictions(x_train, x_test, train3, test3)\n",
        "print(\"Getting Predictions4\")\n",
        "predictions4, predictions_class4 = getPredictions(x_train, x_test, train4, test4)\n",
        "print(\"Getting Predictions5\")\n",
        "predictions5, predictions_class5 = getPredictions(x_train, x_test, train5, test5)\n",
        "print(\"Getting Predictions6\")\n",
        "predictions6, predictions_class6 = getPredictions(x_train, x_test, train6, test6)\n",
        "print(\"Getting Predictions7\")\n",
        "predictions7, predictions_class7 = getPredictions(x_train, x_test, train7, test7)\n",
        "print(\"Getting Predictions8\")\n",
        "predictions8, predictions_class8 = getPredictions(x_train, x_test, train8, test8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Predictions1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.3418 - f1: 0.9085 - acc: 0.8631 - val_loss: 0.2349 - val_f1: 0.9355 - val_acc: 0.9175\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.1693 - f1: 0.9571 - acc: 0.9403 - val_loss: 0.2347 - val_f1: 0.9436 - val_acc: 0.9262\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.0738 - f1: 0.9820 - acc: 0.9743 - val_loss: 0.2743 - val_f1: 0.9390 - val_acc: 0.9187\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0219 - f1: 0.9973 - acc: 0.9962 - val_loss: 0.2891 - val_f1: 0.9394 - val_acc: 0.9187\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.0047 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3092 - val_f1: 0.9429 - val_acc: 0.9237\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.0019 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3380 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.0011 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3591 - val_f1: 0.9435 - val_acc: 0.9250\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 17s 5ms/step - loss: 7.0882e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3701 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 4.9978e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3866 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 3.6512e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3930 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 2.7579e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4043 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 2.1088e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4188 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 1.6362e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4304 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 1.2876e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4414 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 17s 5ms/step - loss: 1.0173e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4513 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Getting Predictions2\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.2710 - f1: 0.5699 - acc: 0.8933 - val_loss: 0.1906 - val_f1: 0.7350 - val_acc: 0.9287\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.1000 - f1: 0.8263 - acc: 0.9594 - val_loss: 0.1944 - val_f1: 0.6876 - val_acc: 0.9262\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0388 - f1: 0.9020 - acc: 0.9895 - val_loss: 0.2162 - val_f1: 0.6897 - val_acc: 0.9262\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.0102 - f1: 0.9105 - acc: 0.9984 - val_loss: 0.2408 - val_f1: 0.7096 - val_acc: 0.9262\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0025 - f1: 0.9270 - acc: 1.0000 - val_loss: 0.2656 - val_f1: 0.7110 - val_acc: 0.9275\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0011 - f1: 0.9270 - acc: 1.0000 - val_loss: 0.2859 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 6.5431e-04 - f1: 0.9273 - acc: 1.0000 - val_loss: 0.2982 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 4.4397e-04 - f1: 0.9524 - acc: 1.0000 - val_loss: 0.3121 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 3.1695e-04 - f1: 0.9238 - acc: 1.0000 - val_loss: 0.3193 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 2.3288e-04 - f1: 0.8987 - acc: 1.0000 - val_loss: 0.3277 - val_f1: 0.7110 - val_acc: 0.9275\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 1.7556e-04 - f1: 0.8920 - acc: 1.0000 - val_loss: 0.3386 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 1.3448e-04 - f1: 0.9301 - acc: 1.0000 - val_loss: 0.3468 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 1.0495e-04 - f1: 0.9206 - acc: 1.0000 - val_loss: 0.3536 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 8.2528e-05 - f1: 0.9111 - acc: 1.0000 - val_loss: 0.3610 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 6.5304e-05 - f1: 0.9111 - acc: 1.0000 - val_loss: 0.3682 - val_f1: 0.7085 - val_acc: 0.9262\n",
            "Getting Predictions3\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.2209 - f1: 0.8962 - acc: 0.9270 - val_loss: 0.1651 - val_f1: 0.9520 - val_acc: 0.9650\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0673 - f1: 0.9737 - acc: 0.9806 - val_loss: 0.1408 - val_f1: 0.9412 - val_acc: 0.9550\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0231 - f1: 0.9869 - acc: 0.9943 - val_loss: 0.1597 - val_f1: 0.9526 - val_acc: 0.9662\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 14s 5ms/step - loss: 0.0073 - f1: 0.9895 - acc: 0.9987 - val_loss: 0.1755 - val_f1: 0.9549 - val_acc: 0.9675\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0018 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.1906 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 14s 5ms/step - loss: 7.0453e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.2044 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 3.6669e-04 - f1: 0.9905 - acc: 1.0000 - val_loss: 0.2114 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 2.4707e-04 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.2161 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.8070e-04 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.2259 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.3516e-04 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.2348 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.0449e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.2387 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 8.1372e-05 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.2435 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 6.4025e-05 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.2477 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 5.0853e-05 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.2519 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 4.0797e-05 - f1: 0.9936 - acc: 1.0000 - val_loss: 0.2582 - val_f1: 0.9560 - val_acc: 0.9687\n",
            "Getting Predictions4\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 14s 5ms/step - loss: 0.4626 - f1: 0.4129 - acc: 0.7841 - val_loss: 0.3881 - val_f1: 0.6779 - val_acc: 0.8350\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.2476 - f1: 0.7931 - acc: 0.9092 - val_loss: 0.3955 - val_f1: 0.6612 - val_acc: 0.8275\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0979 - f1: 0.9086 - acc: 0.9698 - val_loss: 0.4065 - val_f1: 0.7068 - val_acc: 0.8425\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0265 - f1: 0.9577 - acc: 0.9962 - val_loss: 0.5272 - val_f1: 0.6542 - val_acc: 0.8250\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 0.0070 - f1: 0.9642 - acc: 0.9994 - val_loss: 0.5800 - val_f1: 0.6789 - val_acc: 0.8325\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0023 - f1: 0.9746 - acc: 1.0000 - val_loss: 0.6213 - val_f1: 0.6727 - val_acc: 0.8300\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 0.0013 - f1: 0.9809 - acc: 1.0000 - val_loss: 0.6478 - val_f1: 0.6748 - val_acc: 0.8312\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 8.4120e-04 - f1: 0.9809 - acc: 1.0000 - val_loss: 0.6557 - val_f1: 0.6834 - val_acc: 0.8325\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 5.9819e-04 - f1: 0.9714 - acc: 1.0000 - val_loss: 0.6811 - val_f1: 0.6824 - val_acc: 0.8325\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 4.3522e-04 - f1: 0.9778 - acc: 1.0000 - val_loss: 0.7060 - val_f1: 0.6778 - val_acc: 0.8300\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 3.2713e-04 - f1: 0.9778 - acc: 1.0000 - val_loss: 0.7213 - val_f1: 0.6801 - val_acc: 0.8312\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 2.5145e-04 - f1: 0.9682 - acc: 1.0000 - val_loss: 0.7395 - val_f1: 0.6801 - val_acc: 0.8312\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.9544e-04 - f1: 0.9746 - acc: 1.0000 - val_loss: 0.7562 - val_f1: 0.6801 - val_acc: 0.8312\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.5396e-04 - f1: 0.9682 - acc: 1.0000 - val_loss: 0.7760 - val_f1: 0.6737 - val_acc: 0.8287\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 1.2231e-04 - f1: 0.9682 - acc: 1.0000 - val_loss: 0.7908 - val_f1: 0.6737 - val_acc: 0.8287\n",
            "Getting Predictions5\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 14s 5ms/step - loss: 0.2461 - f1: 0.5725 - acc: 0.8949 - val_loss: 0.1710 - val_f1: 0.7550 - val_acc: 0.9300\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.1009 - f1: 0.8199 - acc: 0.9635 - val_loss: 0.1521 - val_f1: 0.7683 - val_acc: 0.9362\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 0.0457 - f1: 0.8600 - acc: 0.9841 - val_loss: 0.1672 - val_f1: 0.7722 - val_acc: 0.9350\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0158 - f1: 0.8649 - acc: 0.9952 - val_loss: 0.1959 - val_f1: 0.7392 - val_acc: 0.9287\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0041 - f1: 0.8984 - acc: 1.0000 - val_loss: 0.2050 - val_f1: 0.7490 - val_acc: 0.9312\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 0.0013 - f1: 0.9174 - acc: 1.0000 - val_loss: 0.2178 - val_f1: 0.7473 - val_acc: 0.9300\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 6.7242e-04 - f1: 0.9047 - acc: 1.0000 - val_loss: 0.2251 - val_f1: 0.7511 - val_acc: 0.9312\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 4.3474e-04 - f1: 0.8825 - acc: 1.0000 - val_loss: 0.2324 - val_f1: 0.7470 - val_acc: 0.9287\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 2.9593e-04 - f1: 0.9079 - acc: 1.0000 - val_loss: 0.2408 - val_f1: 0.7535 - val_acc: 0.9325\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 2.1542e-04 - f1: 0.8889 - acc: 1.0000 - val_loss: 0.2452 - val_f1: 0.7495 - val_acc: 0.9300\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.6250e-04 - f1: 0.9238 - acc: 1.0000 - val_loss: 0.2531 - val_f1: 0.7535 - val_acc: 0.9325\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.2561e-04 - f1: 0.9178 - acc: 1.0000 - val_loss: 0.2577 - val_f1: 0.7470 - val_acc: 0.9287\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 9.6917e-05 - f1: 0.8796 - acc: 1.0000 - val_loss: 0.2636 - val_f1: 0.7487 - val_acc: 0.9300\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 7.6367e-05 - f1: 0.8634 - acc: 1.0000 - val_loss: 0.2688 - val_f1: 0.7487 - val_acc: 0.9300\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 6.1118e-05 - f1: 0.8825 - acc: 1.0000 - val_loss: 0.2725 - val_f1: 0.7470 - val_acc: 0.9287\n",
            "Getting Predictions6\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 0.1874 - f1: 0.2910 - acc: 0.9320 - val_loss: 0.0980 - val_f1: 0.5508 - val_acc: 0.9550\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0694 - f1: 0.5941 - acc: 0.9755 - val_loss: 0.0867 - val_f1: 0.5687 - val_acc: 0.9600\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0298 - f1: 0.6317 - acc: 0.9905 - val_loss: 0.1039 - val_f1: 0.5308 - val_acc: 0.9562\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0142 - f1: 0.6218 - acc: 0.9949 - val_loss: 0.0966 - val_f1: 0.5337 - val_acc: 0.9550\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0036 - f1: 0.6807 - acc: 0.9990 - val_loss: 0.1230 - val_f1: 0.4667 - val_acc: 0.9487\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 8.7881e-04 - f1: 0.6539 - acc: 1.0000 - val_loss: 0.1143 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 3.8693e-04 - f1: 0.6793 - acc: 1.0000 - val_loss: 0.1169 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 2.5891e-04 - f1: 0.6443 - acc: 1.0000 - val_loss: 0.1207 - val_f1: 0.5187 - val_acc: 0.9525\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.9018e-04 - f1: 0.6542 - acc: 1.0000 - val_loss: 0.1228 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.4356e-04 - f1: 0.7110 - acc: 1.0000 - val_loss: 0.1250 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 1.1079e-04 - f1: 0.6793 - acc: 1.0000 - val_loss: 0.1274 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 8.7062e-05 - f1: 0.6605 - acc: 1.0000 - val_loss: 0.1294 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 6.9178e-05 - f1: 0.6574 - acc: 1.0000 - val_loss: 0.1317 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 5.5461e-05 - f1: 0.6316 - acc: 1.0000 - val_loss: 0.1338 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 4.4855e-05 - f1: 0.6761 - acc: 1.0000 - val_loss: 0.1362 - val_f1: 0.5229 - val_acc: 0.9537\n",
            "Getting Predictions7\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.1313 - f1: 0.6250 - acc: 0.9562 - val_loss: 0.0630 - val_f1: 0.7869 - val_acc: 0.9862\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 14s 5ms/step - loss: 0.0312 - f1: 0.7752 - acc: 0.9908 - val_loss: 0.0548 - val_f1: 0.7703 - val_acc: 0.9837\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 0.0109 - f1: 0.7677 - acc: 0.9959 - val_loss: 0.0755 - val_f1: 0.7869 - val_acc: 0.9862\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 0.0029 - f1: 0.8211 - acc: 0.9994 - val_loss: 0.0605 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 7.2834e-04 - f1: 0.7618 - acc: 1.0000 - val_loss: 0.0601 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 14s 4ms/step - loss: 3.6743e-04 - f1: 0.7936 - acc: 1.0000 - val_loss: 0.0642 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 13s 4ms/step - loss: 2.3805e-04 - f1: 0.7812 - acc: 1.0000 - val_loss: 0.0676 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 1.6540e-04 - f1: 0.8285 - acc: 1.0000 - val_loss: 0.0701 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 1.2039e-04 - f1: 0.8161 - acc: 1.0000 - val_loss: 0.0736 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 9.1899e-05 - f1: 0.7936 - acc: 1.0000 - val_loss: 0.0742 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 6.9954e-05 - f1: 0.7968 - acc: 1.0000 - val_loss: 0.0767 - val_f1: 0.7761 - val_acc: 0.9850\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 5.4145e-05 - f1: 0.8095 - acc: 1.0000 - val_loss: 0.0794 - val_f1: 0.7761 - val_acc: 0.9850\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 4.2978e-05 - f1: 0.7999 - acc: 1.0000 - val_loss: 0.0788 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 3.4347e-05 - f1: 0.8161 - acc: 1.0000 - val_loss: 0.0819 - val_f1: 0.7761 - val_acc: 0.9850\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 2.7307e-05 - f1: 0.8031 - acc: 1.0000 - val_loss: 0.0818 - val_f1: 0.7786 - val_acc: 0.9862\n",
            "Getting Predictions8\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 17s 5ms/step - loss: 0.2358 - f1: 0.2298 - acc: 0.9238 - val_loss: 0.0774 - val_f1: 0.5158 - val_acc: 0.9812\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0676 - f1: 0.6144 - acc: 0.9790 - val_loss: 0.0689 - val_f1: 0.5115 - val_acc: 0.9787\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0363 - f1: 0.6297 - acc: 0.9895 - val_loss: 0.0758 - val_f1: 0.4657 - val_acc: 0.9737\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 0.0166 - f1: 0.6602 - acc: 0.9956 - val_loss: 0.0747 - val_f1: 0.4990 - val_acc: 0.9750\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0055 - f1: 0.6994 - acc: 0.9990 - val_loss: 0.0812 - val_f1: 0.4740 - val_acc: 0.9737\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 0.0024 - f1: 0.6475 - acc: 0.9997 - val_loss: 0.0801 - val_f1: 0.5115 - val_acc: 0.9775\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 7.4502e-04 - f1: 0.6793 - acc: 1.0000 - val_loss: 0.0888 - val_f1: 0.4699 - val_acc: 0.9725\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 3.9395e-04 - f1: 0.6542 - acc: 1.0000 - val_loss: 0.0932 - val_f1: 0.4699 - val_acc: 0.9725\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 16s 5ms/step - loss: 2.5831e-04 - f1: 0.6539 - acc: 1.0000 - val_loss: 0.0964 - val_f1: 0.4699 - val_acc: 0.9725\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 1.8650e-04 - f1: 0.6732 - acc: 1.0000 - val_loss: 0.1001 - val_f1: 0.4699 - val_acc: 0.9725\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 1.3762e-04 - f1: 0.6478 - acc: 1.0000 - val_loss: 0.1033 - val_f1: 0.4699 - val_acc: 0.9725\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 1.0448e-04 - f1: 0.6602 - acc: 1.0000 - val_loss: 0.1059 - val_f1: 0.4699 - val_acc: 0.9725\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 8.1602e-05 - f1: 0.6605 - acc: 1.0000 - val_loss: 0.1087 - val_f1: 0.4699 - val_acc: 0.9725\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 17s 5ms/step - loss: 6.3741e-05 - f1: 0.6701 - acc: 1.0000 - val_loss: 0.1110 - val_f1: 0.4824 - val_acc: 0.9737\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 15s 5ms/step - loss: 5.0186e-05 - f1: 0.6507 - acc: 1.0000 - val_loss: 0.1141 - val_f1: 0.4699 - val_acc: 0.9725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OUodWrp4q6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions1 = predictions1[:, 0]\n",
        "predictions_class1 = predictions_class1[:, 0]\n",
        "\n",
        "predictions2 = predictions2[:, 0]\n",
        "predictions_class2 = predictions_class2[:, 0]\n",
        "\n",
        "predictions3 = predictions3[:, 0]\n",
        "predictions_class3 = predictions_class3[:, 0]\n",
        "\n",
        "predictions4 = predictions4[:, 0]\n",
        "predictions_class4 = predictions_class4[:, 0]\n",
        "\n",
        "predictions5 = predictions5[:, 0]\n",
        "predictions_class5 = predictions_class5[:, 0]\n",
        "\n",
        "predictions6 = predictions6[:, 0]\n",
        "predictions_class6 = predictions_class6[:, 0]\n",
        "\n",
        "predictions7 = predictions7[:, 0]\n",
        "predictions_class7 = predictions_class7[:, 0]\n",
        "\n",
        "predictions8 = predictions8[:, 0]\n",
        "predictions_class8 = predictions_class8[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7amu7uH54rl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8R8Jqdl4tl5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b5f0d60c-18d9-4b49-c294-dd37f065f217"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy1 = accuracy_score(test1, predictions_class1)\n",
        "accuracy2 = accuracy_score(test2, predictions_class2)\n",
        "accuracy3 = accuracy_score(test3, predictions_class3)\n",
        "accuracy4 = accuracy_score(test4, predictions_class4)\n",
        "accuracy5 = accuracy_score(test5, predictions_class5)\n",
        "accuracy6 = accuracy_score(test6, predictions_class6)\n",
        "accuracy7 = accuracy_score(test7, predictions_class7)\n",
        "accuracy8 = accuracy_score(test8, predictions_class8)\n",
        "\n",
        "final_accuracy = (accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy5 + accuracy6 + accuracy7 + accuracy8) / 8\n",
        "final_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93640625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixB3uvmp4wD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "75a99601-0f2a-457b-d8cb-5bd30b4b8f87"
      },
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision1 = precision_score(test1, predictions_class1)\n",
        "precision2 = precision_score(test2, predictions_class2)\n",
        "precision3 = precision_score(test3, predictions_class3)\n",
        "precision4 = precision_score(test4, predictions_class4)\n",
        "precision5 = precision_score(test5, predictions_class5)\n",
        "precision6 = precision_score(test6, predictions_class6)\n",
        "precision7 = precision_score(test7, predictions_class7)\n",
        "precision8 = precision_score(test8, predictions_class8)\n",
        "\n",
        "final_precision_score = (precision1 + precision2 + precision3 + precision4 + precision5 + precision6 + precision7 + precision8) / 8\n",
        "final_precision_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8609090466822296"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_ZW5ny34yWw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58e7d8fe-13eb-4949-a8ca-691837ca038e"
      },
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall1 = recall_score(test1, predictions_class1)\n",
        "recall2 = recall_score(test2, predictions_class2)\n",
        "recall3 = recall_score(test3, predictions_class3)\n",
        "recall4 = recall_score(test4, predictions_class4)\n",
        "recall5 = recall_score(test5, predictions_class5)\n",
        "recall6 = recall_score(test6, predictions_class6)\n",
        "recall7 = recall_score(test7, predictions_class7)\n",
        "recall8 = recall_score(test8, predictions_class8)\n",
        "\n",
        "final_recall_score = (recall1 + recall2 + recall3 + recall4 + recall5 + recall6 + recall7 + recall8) / 8\n",
        "final_recall_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8536651937336079"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow8AUOkX40hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28676f2b-d3e3-451b-f0b8-6c5bb42c51de"
      },
      "source": [
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1_score1 = f1_score(test1, predictions_class1)\n",
        "f1_score2 = f1_score(test2, predictions_class2)\n",
        "f1_score3 = f1_score(test3, predictions_class3)\n",
        "f1_score4 = f1_score(test4, predictions_class4)\n",
        "f1_score5 = f1_score(test5, predictions_class5)\n",
        "f1_score6 = f1_score(test6, predictions_class6)\n",
        "f1_score7 = f1_score(test7, predictions_class7)\n",
        "f1_score8 = f1_score(test8, predictions_class8)\n",
        "\n",
        "final_f1_score = (f1_score1 + f1_score2 + f1_score3 + f1_score4 + f1_score5 + f1_score6 + f1_score7 + f1_score8) / 8\n",
        "final_f1_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8560281574616657"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi8e0hFK42-t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "313b5854-69c1-49fe-aefc-50f6a3b93983"
      },
      "source": [
        "# ROC AUC\n",
        "auc1 = roc_auc_score(test1, predictions_class1)\n",
        "auc2 = roc_auc_score(test2, predictions_class2)\n",
        "auc3 = roc_auc_score(test3, predictions_class3)\n",
        "auc4 = roc_auc_score(test4, predictions_class4)\n",
        "auc5 = roc_auc_score(test5, predictions_class5)\n",
        "auc6 = roc_auc_score(test6, predictions_class6)\n",
        "auc7 = roc_auc_score(test7, predictions_class7)\n",
        "auc8 = roc_auc_score(test8, predictions_class8)\n",
        "\n",
        "final_auc = (auc1 + auc2 + auc3 + auc4 + auc5 + auc6 + auc7 + auc8) / 8\n",
        "final_auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9000274882646868"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}