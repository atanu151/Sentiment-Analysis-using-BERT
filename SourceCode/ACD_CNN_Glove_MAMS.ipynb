{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACD_CNN_Glove_MAMS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2P_Sj3PaQcZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82LJTCzgbdG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KR1U3emCw_3c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9cb7c62-a5ea-409d-c0e1-0eaa72361510"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/Aspect Category Detection/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wisxz0cJv4d4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8077913b-2e88-4735-85b2-e9fb2d3a44f5"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import layers\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET, getopt, logging, sys, random, re, copy, os\n",
        "from lxml import etree\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnakIYxKwPas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getSentences(file):\n",
        "  tree = ET.parse(file, etree.XMLParser(recover=True, encoding=\"utf-8\"))\n",
        "  root = tree.getroot()\n",
        "  s = []\n",
        "  p = []\n",
        "  #for review in root.findall('Review'):\n",
        "  for sentence in root.findall('sentence'):\n",
        "    #for sentence in sentences.findall('sentence'):\n",
        "    sent = []\n",
        "    sent_characteristics = []\n",
        "    text = sentence.find('text').text\n",
        "    sent.append(text)\n",
        "    polarity = []\n",
        "    for opinions in sentence.findall('aspectCategories'):\n",
        "      for opinion in opinions.findall('aspectCategory'):\n",
        "        elem = [opinion.get('category'), opinion.get('polarity')]\n",
        "        polarity.append(elem)\n",
        "    sent_characteristics.append(polarity)\n",
        "    s.append(sent)\n",
        "    p.append(sent_characteristics)\n",
        "        \n",
        "  return s, p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CvYhyZVwSnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences, train_adnotations = getSentences(\"./MAMS_train.xml\")\n",
        "test_sentences, test_adnotations = getSentences(\"./MAMS_test.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJyAKgsGxZwC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "bd9accca-07a9-4b3e-e965-026773250ca1"
      },
      "source": [
        "train_sentences[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"It might be the best sit down food I've had in the area, so if you are going to the upright citizen brigade, or the garden, it could be just the place for you.\"],\n",
              " ['Hostess was extremely accommodating when we arrived an hour early for our reservation.'],\n",
              " [\"We were a couple of minutes late for our reservation and minus one guest, but we didn't think we deserved the attitude we got from the hostess.\"],\n",
              " ['Though the service might be a little slow, the waitresses are very friendly.'],\n",
              " ['Although we arrived at the restaurant 10 min late, the hostess did not have a table for us.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCYoUwjCxjoA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "1cac2e6a-b89e-4378-9422-f941bde0e568"
      },
      "source": [
        "train_adnotations [0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[['food', 'positive'], ['place', 'neutral']]],\n",
              " [[['staff', 'positive'], ['miscellaneous', 'neutral']]],\n",
              " [[['miscellaneous', 'neutral'], ['staff', 'negative']]],\n",
              " [[['service', 'negative'], ['staff', 'positive']]],\n",
              " [[['staff', 'negative'], ['miscellaneous', 'neutral']]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dl8b8oJxnHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_reviews = []\n",
        "train_aspects = []\n",
        "test_reviews = []\n",
        "test_aspects = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG1e-rSUxpxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in train_sentences:\n",
        "  train_reviews.append(' '.join(review))\n",
        "for ta in train_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  train_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHU3VwhLx025",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in test_sentences:\n",
        "  test_reviews.append(' '.join(review))\n",
        "  \n",
        "for ta in test_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  test_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtsKdUDUx4KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLabels(aspects):\n",
        "\t#print(unique_aspects)\n",
        "\t#Create train labels\n",
        "\tfood = []\n",
        "\tplace = []\n",
        "\tstaff = []\n",
        "\tmiscellaneous = []\n",
        "\tservice\t= []\n",
        "\tmenu = []\n",
        "\tambience = []\n",
        "\tprice = []\n",
        "\n",
        "\tfor aspect in aspects:\n",
        "\t\tif 'food' in aspect:\n",
        "\t\t\tfood.append(1)\n",
        "\t\telse:\n",
        "\t\t\tfood.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'place' in aspect:\n",
        "\t\t\tplace.append(1)\n",
        "\t\telse:\n",
        "\t\t\tplace.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'staff' in aspect:\n",
        "\t\t\tstaff.append(1)\n",
        "\t\telse:\n",
        "\t\t\tstaff.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'miscellaneous' in aspect:\n",
        "\t\t\tmiscellaneous.append(1)\n",
        "\t\telse:\n",
        "\t\t\tmiscellaneous.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'service' in aspect:\n",
        "\t\t\tservice.append(1)\n",
        "\t\telse:\n",
        "\t\t\tservice.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'menu' in aspect:\n",
        "\t\t\tmenu.append(1)\n",
        "\t\telse:\n",
        "\t\t\tmenu.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'ambience' in aspect:\n",
        "\t\t\tambience.append(1)\n",
        "\t\telse:\n",
        "\t\t\tambience.append(0)\n",
        "\t\t\t\n",
        "\t\tif 'price' in aspect:\n",
        "\t\t\tprice.append(1)\n",
        "\t\telse:\n",
        "\t\t\tprice.append(0)\n",
        "\t\t\t\t\n",
        "\treturn food, place ,staff , miscellaneous ,service ,price ,menu , ambience"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_3v8HYgx9do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train and test labels\n",
        "train1, train2, train3, train4, train5, train6, train7, train8 = getLabels(train_aspects)\n",
        "train_labels = [train1, train2, train3, train4, train5, train6, train7, train8]\n",
        "\n",
        "test1, test2, test3, test4, test5, test6, test7, test8 = getLabels(test_aspects)\n",
        "test_labels = [test1, test2, test3, test4, test5, test6, test7, test8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3sksHgcyAt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vectorizing data\n",
        "vectorizer = CountVectorizer(analyzer='word', lowercase=True, stop_words='english', ngram_range=(1,2))\n",
        "vectorizer.fit(train_reviews)\n",
        "x_train = vectorizer.transform(train_reviews)\n",
        "x_test = vectorizer.transform(test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-VSAkkIyH5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[1]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(train_reviews)\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(train_reviews)\n",
        "x_test = tokenizer.texts_to_sequences(test_reviews)\n",
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWqjSPQByNpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 100\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding = 'post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEWQWUfiyZLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pretrained Word Embeddings\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "\tvocab_size = len(word_index) + 1\n",
        "\tembedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\t\n",
        "\twith open(filepath, encoding='utf-8') as f:\n",
        "\t\tfor line in f:\n",
        "\t\t\tword, *vector = line.split()\n",
        "\t\t\tif word in word_index:\n",
        "\t\t\t\tidx = word_index[word]\n",
        "\t\t\t\tembedding_matrix[idx] = np.array(vector[-300:], dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "\treturn embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thzJzWUKygEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = create_embedding_matrix('./glove.840B.300d.txt', tokenizer.word_index, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJmDTvItzIwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        Only computes a batch-wise average of recall.\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "        Only computes a batch-wise average of precision.\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLR9MWTWzL3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "def getPredictions(x_train, x_test, train, test):\n",
        "\tembedding_dim = 300\n",
        "\tembedding_matrix = create_embedding_matrix('./glove.840B.300d.txt', tokenizer.word_index, embedding_dim)\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length = maxlen, trainable = True))\n",
        "\tmodel.add(layers.Conv1D(64, 3, activation = 'relu'))\n",
        "\tmodel.add(layers.GlobalMaxPool1D())\n",
        "\tmodel.add(layers.Dense(10, activation='relu'))\n",
        "\tmodel.add(layers.Dense(1, activation='sigmoid'))\n",
        "\tmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1, 'accuracy'])\n",
        "\t#model.summary()\n",
        "\n",
        "\thistory = model.fit(x_train, train, epochs = 15, verbose = 1, validation_data = (x_test, test), batch_size = 10)\n",
        "\tval = model.evaluate(x_train, train, verbose = False)\n",
        "\tval = model.evaluate(x_test, test, verbose = False)\n",
        "\n",
        "\tpredictions = model.predict(x_test)\n",
        "\tpredictions_class = model.predict_classes(x_test)\n",
        "\t#predictions1 = model.predict(testt)\n",
        "\t#predictions11 = model.predict_classes(testt)\n",
        "\treturn predictions, predictions_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SANpFQgczmsA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ddf697d0-d63d-42f8-ceb5-95b635b32528"
      },
      "source": [
        "print(\"Getting Predictions1\")\n",
        "predictions1, predictions_class1 = getPredictions(x_train, x_test, train1, test1)\n",
        "print(\"Getting Predictions2\")\n",
        "predictions2, predictions_class2 = getPredictions(x_train, x_test, train2, test2)\n",
        "print(\"Getting Predictions3\")\n",
        "predictions3, predictions_class3 = getPredictions(x_train, x_test, train3, test3)\n",
        "print(\"Getting Predictions4\")\n",
        "predictions4, predictions_class4 = getPredictions(x_train, x_test, train4, test4)\n",
        "print(\"Getting Predictions5\")\n",
        "predictions5, predictions_class5 = getPredictions(x_train, x_test, train5, test5)\n",
        "print(\"Getting Predictions6\")\n",
        "predictions6, predictions_class6 = getPredictions(x_train, x_test, train6, test6)\n",
        "print(\"Getting Predictions7\")\n",
        "predictions7, predictions_class7 = getPredictions(x_train, x_test, train7, test7)\n",
        "print(\"Getting Predictions8\")\n",
        "predictions8, predictions_class8 = getPredictions(x_train, x_test, train8, test8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Predictions1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 10s 3ms/step - loss: 0.3567 - f1: 0.9051 - acc: 0.8568 - val_loss: 0.2467 - val_f1: 0.9342 - val_acc: 0.9112\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 884us/step - loss: 0.2026 - f1: 0.9510 - acc: 0.9317 - val_loss: 0.2397 - val_f1: 0.9412 - val_acc: 0.9225\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 901us/step - loss: 0.1140 - f1: 0.9710 - acc: 0.9606 - val_loss: 0.2419 - val_f1: 0.9442 - val_acc: 0.9262\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 903us/step - loss: 0.0517 - f1: 0.9899 - acc: 0.9860 - val_loss: 0.2879 - val_f1: 0.9280 - val_acc: 0.9062\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 955us/step - loss: 0.0196 - f1: 0.9979 - acc: 0.9968 - val_loss: 0.3459 - val_f1: 0.9417 - val_acc: 0.9225\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 960us/step - loss: 0.0085 - f1: 0.9996 - acc: 0.9994 - val_loss: 0.3198 - val_f1: 0.9401 - val_acc: 0.9212\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 961us/step - loss: 0.0054 - f1: 0.9995 - acc: 0.9994 - val_loss: 0.3340 - val_f1: 0.9428 - val_acc: 0.9250\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 947us/step - loss: 0.0034 - f1: 0.9996 - acc: 0.9997 - val_loss: 0.3489 - val_f1: 0.9387 - val_acc: 0.9187\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 934us/step - loss: 0.0014 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3774 - val_f1: 0.9401 - val_acc: 0.9212\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 945us/step - loss: 6.6765e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.3908 - val_f1: 0.9413 - val_acc: 0.9225\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 938us/step - loss: 4.6397e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4025 - val_f1: 0.9426 - val_acc: 0.9237\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 919us/step - loss: 3.4544e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4184 - val_f1: 0.9432 - val_acc: 0.9250\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 939us/step - loss: 2.6025e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4227 - val_f1: 0.9426 - val_acc: 0.9237\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 947us/step - loss: 2.0431e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4365 - val_f1: 0.9423 - val_acc: 0.9237\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 924us/step - loss: 1.6073e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.4417 - val_f1: 0.9435 - val_acc: 0.9250\n",
            "Getting Predictions2\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 4s 1ms/step - loss: 0.2950 - f1: 0.4931 - acc: 0.8688 - val_loss: 0.2146 - val_f1: 0.6789 - val_acc: 0.9100\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 963us/step - loss: 0.1163 - f1: 0.8111 - acc: 0.9559 - val_loss: 0.2060 - val_f1: 0.6853 - val_acc: 0.9175\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 964us/step - loss: 0.0487 - f1: 0.8839 - acc: 0.9886 - val_loss: 0.1929 - val_f1: 0.7213 - val_acc: 0.9212\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 972us/step - loss: 0.0197 - f1: 0.8831 - acc: 0.9962 - val_loss: 0.2143 - val_f1: 0.7359 - val_acc: 0.9262\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 979us/step - loss: 0.0066 - f1: 0.9130 - acc: 0.9994 - val_loss: 0.2385 - val_f1: 0.7198 - val_acc: 0.9250\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 966us/step - loss: 0.0020 - f1: 0.9174 - acc: 1.0000 - val_loss: 0.2580 - val_f1: 0.7187 - val_acc: 0.9237\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 983us/step - loss: 0.0011 - f1: 0.9174 - acc: 1.0000 - val_loss: 0.2731 - val_f1: 0.7156 - val_acc: 0.9275\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 972us/step - loss: 6.8600e-04 - f1: 0.9143 - acc: 1.0000 - val_loss: 0.2812 - val_f1: 0.7081 - val_acc: 0.9212\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 970us/step - loss: 4.8115e-04 - f1: 0.9079 - acc: 1.0000 - val_loss: 0.2911 - val_f1: 0.7187 - val_acc: 0.9237\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 971us/step - loss: 3.4553e-04 - f1: 0.9047 - acc: 1.0000 - val_loss: 0.2985 - val_f1: 0.7187 - val_acc: 0.9237\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 977us/step - loss: 2.5920e-04 - f1: 0.9365 - acc: 1.0000 - val_loss: 0.3078 - val_f1: 0.7187 - val_acc: 0.9237\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 969us/step - loss: 1.9816e-04 - f1: 0.9016 - acc: 1.0000 - val_loss: 0.3128 - val_f1: 0.7095 - val_acc: 0.9225\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 960us/step - loss: 1.5463e-04 - f1: 0.9238 - acc: 1.0000 - val_loss: 0.3223 - val_f1: 0.7187 - val_acc: 0.9237\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 963us/step - loss: 1.2206e-04 - f1: 0.9143 - acc: 1.0000 - val_loss: 0.3283 - val_f1: 0.7176 - val_acc: 0.9225\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 978us/step - loss: 9.6231e-05 - f1: 0.9111 - acc: 1.0000 - val_loss: 0.3343 - val_f1: 0.7176 - val_acc: 0.9225\n",
            "Getting Predictions3\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 4s 1ms/step - loss: 0.2081 - f1: 0.8873 - acc: 0.9254 - val_loss: 0.1537 - val_f1: 0.9365 - val_acc: 0.9537\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 982us/step - loss: 0.0721 - f1: 0.9668 - acc: 0.9762 - val_loss: 0.1469 - val_f1: 0.9346 - val_acc: 0.9500\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 981us/step - loss: 0.0268 - f1: 0.9897 - acc: 0.9927 - val_loss: 0.1730 - val_f1: 0.9450 - val_acc: 0.9587\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 973us/step - loss: 0.0068 - f1: 0.9990 - acc: 0.9987 - val_loss: 0.1689 - val_f1: 0.9341 - val_acc: 0.9500\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 979us/step - loss: 0.0027 - f1: 0.9994 - acc: 0.9997 - val_loss: 0.1841 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 969us/step - loss: 9.4996e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.1956 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 982us/step - loss: 5.8150e-04 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.2050 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 971us/step - loss: 4.0335e-04 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.2129 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 975us/step - loss: 2.9494e-04 - f1: 0.9936 - acc: 1.0000 - val_loss: 0.2187 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 959us/step - loss: 2.1883e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.2270 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 970us/step - loss: 1.6784e-04 - f1: 0.9968 - acc: 1.0000 - val_loss: 0.2308 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 1.2750e-04 - f1: 1.0000 - acc: 1.0000 - val_loss: 0.2361 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 996us/step - loss: 1.0075e-04 - f1: 0.9936 - acc: 1.0000 - val_loss: 0.2414 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 974us/step - loss: 7.9584e-05 - f1: 0.9936 - acc: 1.0000 - val_loss: 0.2434 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 964us/step - loss: 6.3405e-05 - f1: 0.9905 - acc: 1.0000 - val_loss: 0.2490 - val_f1: 0.9464 - val_acc: 0.9600\n",
            "Getting Predictions4\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 4s 1ms/step - loss: 0.4891 - f1: 0.4218 - acc: 0.7660 - val_loss: 0.4118 - val_f1: 0.6719 - val_acc: 0.8175\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 989us/step - loss: 0.2642 - f1: 0.7613 - acc: 0.9019 - val_loss: 0.4410 - val_f1: 0.6114 - val_acc: 0.8012\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 980us/step - loss: 0.1214 - f1: 0.9024 - acc: 0.9625 - val_loss: 0.4658 - val_f1: 0.6913 - val_acc: 0.8037\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 986us/step - loss: 0.0363 - f1: 0.9589 - acc: 0.9946 - val_loss: 0.5190 - val_f1: 0.6424 - val_acc: 0.8125\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 983us/step - loss: 0.0099 - f1: 0.9711 - acc: 0.9997 - val_loss: 0.5583 - val_f1: 0.6485 - val_acc: 0.8112\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 991us/step - loss: 0.0035 - f1: 0.9809 - acc: 1.0000 - val_loss: 0.5844 - val_f1: 0.6448 - val_acc: 0.8112\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 975us/step - loss: 0.0019 - f1: 0.9873 - acc: 1.0000 - val_loss: 0.6123 - val_f1: 0.6567 - val_acc: 0.8162\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 0.0013 - f1: 0.9714 - acc: 1.0000 - val_loss: 0.6309 - val_f1: 0.6534 - val_acc: 0.8137\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 8.8268e-04 - f1: 0.9746 - acc: 1.0000 - val_loss: 0.6528 - val_f1: 0.6511 - val_acc: 0.8125\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 6.3333e-04 - f1: 0.9682 - acc: 1.0000 - val_loss: 0.6657 - val_f1: 0.6534 - val_acc: 0.8137\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 4.7634e-04 - f1: 0.9682 - acc: 1.0000 - val_loss: 0.6989 - val_f1: 0.6449 - val_acc: 0.8125\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 987us/step - loss: 3.6025e-04 - f1: 0.9778 - acc: 1.0000 - val_loss: 0.7132 - val_f1: 0.6474 - val_acc: 0.8137\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 983us/step - loss: 2.7628e-04 - f1: 0.9714 - acc: 1.0000 - val_loss: 0.7308 - val_f1: 0.6474 - val_acc: 0.8137\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 987us/step - loss: 2.1538e-04 - f1: 0.9873 - acc: 1.0000 - val_loss: 0.7370 - val_f1: 0.6511 - val_acc: 0.8125\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 983us/step - loss: 1.6972e-04 - f1: 0.9778 - acc: 1.0000 - val_loss: 0.7560 - val_f1: 0.6524 - val_acc: 0.8137\n",
            "Getting Predictions5\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 4s 1ms/step - loss: 0.2717 - f1: 0.5604 - acc: 0.9003 - val_loss: 0.1737 - val_f1: 0.7171 - val_acc: 0.9262\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 997us/step - loss: 0.1018 - f1: 0.7812 - acc: 0.9651 - val_loss: 0.1744 - val_f1: 0.6921 - val_acc: 0.9250\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 988us/step - loss: 0.0454 - f1: 0.8743 - acc: 0.9889 - val_loss: 0.1659 - val_f1: 0.7882 - val_acc: 0.9362\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 989us/step - loss: 0.0128 - f1: 0.8881 - acc: 0.9975 - val_loss: 0.1866 - val_f1: 0.7747 - val_acc: 0.9375\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 979us/step - loss: 0.0039 - f1: 0.8952 - acc: 1.0000 - val_loss: 0.1955 - val_f1: 0.7691 - val_acc: 0.9400\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 0.0016 - f1: 0.9238 - acc: 1.0000 - val_loss: 0.2019 - val_f1: 0.7881 - val_acc: 0.9400\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 9.4921e-04 - f1: 0.8634 - acc: 1.0000 - val_loss: 0.2106 - val_f1: 0.7777 - val_acc: 0.9425\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 980us/step - loss: 6.3683e-04 - f1: 0.9270 - acc: 1.0000 - val_loss: 0.2174 - val_f1: 0.7899 - val_acc: 0.9387\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 994us/step - loss: 4.5594e-04 - f1: 0.8892 - acc: 1.0000 - val_loss: 0.2239 - val_f1: 0.7962 - val_acc: 0.9450\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 978us/step - loss: 3.3380e-04 - f1: 0.8698 - acc: 1.0000 - val_loss: 0.2292 - val_f1: 0.7931 - val_acc: 0.9412\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 996us/step - loss: 2.5193e-04 - f1: 0.9301 - acc: 1.0000 - val_loss: 0.2334 - val_f1: 0.7928 - val_acc: 0.9412\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 983us/step - loss: 1.9378e-04 - f1: 0.8984 - acc: 1.0000 - val_loss: 0.2392 - val_f1: 0.7928 - val_acc: 0.9412\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 988us/step - loss: 1.5021e-04 - f1: 0.9174 - acc: 1.0000 - val_loss: 0.2443 - val_f1: 0.7827 - val_acc: 0.9400\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 993us/step - loss: 1.1917e-04 - f1: 0.9016 - acc: 1.0000 - val_loss: 0.2492 - val_f1: 0.7914 - val_acc: 0.9400\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 996us/step - loss: 9.4305e-05 - f1: 0.8984 - acc: 1.0000 - val_loss: 0.2550 - val_f1: 0.7917 - val_acc: 0.9400\n",
            "Getting Predictions6\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 4s 1ms/step - loss: 0.1862 - f1: 0.2907 - acc: 0.9346 - val_loss: 0.1323 - val_f1: 0.4621 - val_acc: 0.9500\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 962us/step - loss: 0.0799 - f1: 0.5520 - acc: 0.9660 - val_loss: 0.1095 - val_f1: 0.4608 - val_acc: 0.9487\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 966us/step - loss: 0.0409 - f1: 0.6135 - acc: 0.9844 - val_loss: 0.1269 - val_f1: 0.4858 - val_acc: 0.9512\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 957us/step - loss: 0.0223 - f1: 0.6402 - acc: 0.9933 - val_loss: 0.1677 - val_f1: 0.3975 - val_acc: 0.9437\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 959us/step - loss: 0.0079 - f1: 0.6533 - acc: 0.9981 - val_loss: 0.1109 - val_f1: 0.5350 - val_acc: 0.9575\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 955us/step - loss: 0.0019 - f1: 0.6539 - acc: 1.0000 - val_loss: 0.1207 - val_f1: 0.5662 - val_acc: 0.9612\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 956us/step - loss: 6.5570e-04 - f1: 0.6539 - acc: 1.0000 - val_loss: 0.1276 - val_f1: 0.5408 - val_acc: 0.9575\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 959us/step - loss: 4.0313e-04 - f1: 0.6443 - acc: 1.0000 - val_loss: 0.1316 - val_f1: 0.5408 - val_acc: 0.9575\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 959us/step - loss: 2.9197e-04 - f1: 0.6570 - acc: 1.0000 - val_loss: 0.1358 - val_f1: 0.5408 - val_acc: 0.9575\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 943us/step - loss: 2.1756e-04 - f1: 0.6796 - acc: 1.0000 - val_loss: 0.1388 - val_f1: 0.5429 - val_acc: 0.9575\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 971us/step - loss: 1.6626e-04 - f1: 0.6729 - acc: 1.0000 - val_loss: 0.1422 - val_f1: 0.5367 - val_acc: 0.9562\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 983us/step - loss: 1.2965e-04 - f1: 0.6666 - acc: 1.0000 - val_loss: 0.1450 - val_f1: 0.5367 - val_acc: 0.9562\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 945us/step - loss: 1.0191e-04 - f1: 0.6669 - acc: 1.0000 - val_loss: 0.1472 - val_f1: 0.5533 - val_acc: 0.9587\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 957us/step - loss: 8.1521e-05 - f1: 0.6634 - acc: 1.0000 - val_loss: 0.1500 - val_f1: 0.5533 - val_acc: 0.9587\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 945us/step - loss: 6.4848e-05 - f1: 0.6507 - acc: 1.0000 - val_loss: 0.1529 - val_f1: 0.5533 - val_acc: 0.9587\n",
            "Getting Predictions7\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 4s 1ms/step - loss: 0.1272 - f1: 0.5879 - acc: 0.9505 - val_loss: 0.0536 - val_f1: 0.7869 - val_acc: 0.9862\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 977us/step - loss: 0.0479 - f1: 0.7750 - acc: 0.9851 - val_loss: 0.0634 - val_f1: 0.7852 - val_acc: 0.9850\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 977us/step - loss: 0.0379 - f1: 0.8064 - acc: 0.9892 - val_loss: 0.0505 - val_f1: 0.7869 - val_acc: 0.9862\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 993us/step - loss: 0.0274 - f1: 0.8129 - acc: 0.9911 - val_loss: 0.0520 - val_f1: 0.7869 - val_acc: 0.9862\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 976us/step - loss: 0.0119 - f1: 0.7832 - acc: 0.9965 - val_loss: 0.0500 - val_f1: 0.7755 - val_acc: 0.9837\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 972us/step - loss: 0.0023 - f1: 0.8031 - acc: 1.0000 - val_loss: 0.0650 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 978us/step - loss: 7.0067e-04 - f1: 0.7872 - acc: 1.0000 - val_loss: 0.0706 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 979us/step - loss: 3.1659e-04 - f1: 0.8003 - acc: 1.0000 - val_loss: 0.0747 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 970us/step - loss: 1.9926e-04 - f1: 0.8034 - acc: 1.0000 - val_loss: 0.0793 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 974us/step - loss: 1.4565e-04 - f1: 0.7939 - acc: 1.0000 - val_loss: 0.0775 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 1.0646e-04 - f1: 0.7999 - acc: 1.0000 - val_loss: 0.0834 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 8.0720e-05 - f1: 0.8158 - acc: 1.0000 - val_loss: 0.0850 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 1ms/step - loss: 6.2615e-05 - f1: 0.7777 - acc: 1.0000 - val_loss: 0.0849 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 980us/step - loss: 4.9044e-05 - f1: 0.8063 - acc: 1.0000 - val_loss: 0.0863 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 961us/step - loss: 3.8916e-05 - f1: 0.8253 - acc: 1.0000 - val_loss: 0.0890 - val_f1: 0.7719 - val_acc: 0.9837\n",
            "Getting Predictions8\n",
            "Train on 3149 samples, validate on 800 samples\n",
            "Epoch 1/15\n",
            "3149/3149 [==============================] - 4s 1ms/step - loss: 0.1575 - f1: 0.4090 - acc: 0.9476 - val_loss: 0.0694 - val_f1: 0.5100 - val_acc: 0.9775\n",
            "Epoch 2/15\n",
            "3149/3149 [==============================] - 3s 993us/step - loss: 0.0580 - f1: 0.5672 - acc: 0.9803 - val_loss: 0.0808 - val_f1: 0.5415 - val_acc: 0.9775\n",
            "Epoch 3/15\n",
            "3149/3149 [==============================] - 3s 973us/step - loss: 0.0235 - f1: 0.6707 - acc: 0.9940 - val_loss: 0.0738 - val_f1: 0.4608 - val_acc: 0.9725\n",
            "Epoch 4/15\n",
            "3149/3149 [==============================] - 3s 990us/step - loss: 0.0067 - f1: 0.6919 - acc: 0.9987 - val_loss: 0.0844 - val_f1: 0.4650 - val_acc: 0.9737\n",
            "Epoch 5/15\n",
            "3149/3149 [==============================] - 3s 985us/step - loss: 0.0019 - f1: 0.6655 - acc: 0.9997 - val_loss: 0.0753 - val_f1: 0.4883 - val_acc: 0.9775\n",
            "Epoch 6/15\n",
            "3149/3149 [==============================] - 3s 975us/step - loss: 8.4789e-04 - f1: 0.6951 - acc: 1.0000 - val_loss: 0.0836 - val_f1: 0.4758 - val_acc: 0.9762\n",
            "Epoch 7/15\n",
            "3149/3149 [==============================] - 3s 981us/step - loss: 3.9328e-04 - f1: 0.6828 - acc: 1.0000 - val_loss: 0.0820 - val_f1: 0.4883 - val_acc: 0.9775\n",
            "Epoch 8/15\n",
            "3149/3149 [==============================] - 3s 976us/step - loss: 2.5258e-04 - f1: 0.6764 - acc: 1.0000 - val_loss: 0.0850 - val_f1: 0.4883 - val_acc: 0.9775\n",
            "Epoch 9/15\n",
            "3149/3149 [==============================] - 3s 980us/step - loss: 1.7921e-04 - f1: 0.6288 - acc: 1.0000 - val_loss: 0.0873 - val_f1: 0.4883 - val_acc: 0.9762\n",
            "Epoch 10/15\n",
            "3149/3149 [==============================] - 3s 984us/step - loss: 1.3045e-04 - f1: 0.6729 - acc: 1.0000 - val_loss: 0.0901 - val_f1: 0.4883 - val_acc: 0.9775\n",
            "Epoch 11/15\n",
            "3149/3149 [==============================] - 3s 977us/step - loss: 9.8370e-05 - f1: 0.6701 - acc: 1.0000 - val_loss: 0.0922 - val_f1: 0.4883 - val_acc: 0.9762\n",
            "Epoch 12/15\n",
            "3149/3149 [==============================] - 3s 983us/step - loss: 7.4998e-05 - f1: 0.6539 - acc: 1.0000 - val_loss: 0.0936 - val_f1: 0.4883 - val_acc: 0.9762\n",
            "Epoch 13/15\n",
            "3149/3149 [==============================] - 3s 990us/step - loss: 5.8197e-05 - f1: 0.6570 - acc: 1.0000 - val_loss: 0.0954 - val_f1: 0.4883 - val_acc: 0.9762\n",
            "Epoch 14/15\n",
            "3149/3149 [==============================] - 3s 972us/step - loss: 4.6180e-05 - f1: 0.6351 - acc: 1.0000 - val_loss: 0.0969 - val_f1: 0.4883 - val_acc: 0.9762\n",
            "Epoch 15/15\n",
            "3149/3149 [==============================] - 3s 967us/step - loss: 3.6332e-05 - f1: 0.6697 - acc: 1.0000 - val_loss: 0.0980 - val_f1: 0.4883 - val_acc: 0.9762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCnxYqhYzwxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions1 = predictions1[:, 0]\n",
        "predictions_class1 = predictions_class1[:, 0]\n",
        "\n",
        "predictions2 = predictions2[:, 0]\n",
        "predictions_class2 = predictions_class2[:, 0]\n",
        "\n",
        "predictions3 = predictions3[:, 0]\n",
        "predictions_class3 = predictions_class3[:, 0]\n",
        "\n",
        "predictions4 = predictions4[:, 0]\n",
        "predictions_class4 = predictions_class4[:, 0]\n",
        "\n",
        "predictions5 = predictions5[:, 0]\n",
        "predictions_class5 = predictions_class5[:, 0]\n",
        "\n",
        "predictions6 = predictions6[:, 0]\n",
        "predictions_class6 = predictions_class6[:, 0]\n",
        "\n",
        "predictions7 = predictions7[:, 0]\n",
        "predictions_class7 = predictions_class7[:, 0]\n",
        "\n",
        "predictions8 = predictions8[:, 0]\n",
        "predictions_class8 = predictions_class8[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRYHX1ncz1yN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmNnMTvez4P7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d9136d53-50dd-4b5e-ff75-c78502c55792"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy1 = accuracy_score(test1, predictions_class1)\n",
        "accuracy2 = accuracy_score(test2, predictions_class2)\n",
        "accuracy3 = accuracy_score(test3, predictions_class3)\n",
        "accuracy4 = accuracy_score(test4, predictions_class4)\n",
        "accuracy5 = accuracy_score(test5, predictions_class5)\n",
        "accuracy6 = accuracy_score(test6, predictions_class6)\n",
        "accuracy7 = accuracy_score(test7, predictions_class7)\n",
        "accuracy8 = accuracy_score(test8, predictions_class8)\n",
        "\n",
        "final_accuracy = (accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy5 + accuracy6 + accuracy7 + accuracy8) / 8\n",
        "final_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9349999999999999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35lJ_OShz7bY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ee986ad8-79d5-4d5d-94dd-a56e41dba987"
      },
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision1 = precision_score(test1, predictions_class1)\n",
        "precision2 = precision_score(test2, predictions_class2)\n",
        "precision3 = precision_score(test3, predictions_class3)\n",
        "precision4 = precision_score(test4, predictions_class4)\n",
        "precision5 = precision_score(test5, predictions_class5)\n",
        "precision6 = precision_score(test6, predictions_class6)\n",
        "precision7 = precision_score(test7, predictions_class7)\n",
        "precision8 = precision_score(test8, predictions_class8)\n",
        "\n",
        "final_precision_score = (precision1 + precision2 + precision3 + precision4 + precision5 + precision6 + precision7 + precision8) / 8\n",
        "final_precision_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8643908433424881"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DqA2Auiz9QM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d793c8cd-c070-430f-8744-79cacf571f8a"
      },
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall1 = recall_score(test1, predictions_class1)\n",
        "recall2 = recall_score(test2, predictions_class2)\n",
        "recall3 = recall_score(test3, predictions_class3)\n",
        "recall4 = recall_score(test4, predictions_class4)\n",
        "recall5 = recall_score(test5, predictions_class5)\n",
        "recall6 = recall_score(test6, predictions_class6)\n",
        "recall7 = recall_score(test7, predictions_class7)\n",
        "recall8 = recall_score(test8, predictions_class8)\n",
        "\n",
        "final_recall_score = (recall1 + recall2 + recall3 + recall4 + recall5 + recall6 + recall7 + recall8) / 8\n",
        "final_recall_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8559661557244651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i85KBr5Cz_KW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7c90ca5-6bc3-4644-83bd-af8c2cb6b5ae"
      },
      "source": [
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1_score1 = f1_score(test1, predictions_class1)\n",
        "f1_score2 = f1_score(test2, predictions_class2)\n",
        "f1_score3 = f1_score(test3, predictions_class3)\n",
        "f1_score4 = f1_score(test4, predictions_class4)\n",
        "f1_score5 = f1_score(test5, predictions_class5)\n",
        "f1_score6 = f1_score(test6, predictions_class6)\n",
        "f1_score7 = f1_score(test7, predictions_class7)\n",
        "f1_score8 = f1_score(test8, predictions_class8)\n",
        "\n",
        "final_f1_score = (f1_score1 + f1_score2 + f1_score3 + f1_score4 + f1_score5 + f1_score6 + f1_score7 + f1_score8) / 8\n",
        "final_f1_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8585907814245815"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw03sxzw0BDw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d8833936-0f32-45f8-adb7-cc2a976d9b40"
      },
      "source": [
        "# ROC AUC\n",
        "auc1 = roc_auc_score(test1, predictions_class1)\n",
        "auc2 = roc_auc_score(test2, predictions_class2)\n",
        "auc3 = roc_auc_score(test3, predictions_class3)\n",
        "auc4 = roc_auc_score(test4, predictions_class4)\n",
        "auc5 = roc_auc_score(test5, predictions_class5)\n",
        "auc6 = roc_auc_score(test6, predictions_class6)\n",
        "auc7 = roc_auc_score(test7, predictions_class7)\n",
        "auc8 = roc_auc_score(test8, predictions_class8)\n",
        "\n",
        "final_auc = (auc1 + auc2 + auc3 + auc4 + auc5 + auc6 + auc7 + auc8) / 8\n",
        "final_auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9009801102567434"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}