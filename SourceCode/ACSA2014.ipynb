{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACSA2014.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4H49t1kh6XC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nPZPDHonp6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d713355-4818-4b93-bb48-3f8ba0fd7f21"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras import layers\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET, getopt, logging, sys, random, re, copy, os\n",
        "from lxml import etree\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8wV8VXQmq2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5535c25-2672-4cf0-ac5e-29a0f0f8b14e"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/SVM/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym-Ee3uInmmM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRPkrawhn2ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getSentences(file):\n",
        "  tree = ET.parse(file, etree.XMLParser(recover=True, encoding=\"utf-8\"))\n",
        "  root = tree.getroot()\n",
        "  s = []\n",
        "  p = []\n",
        "  #for review in root.findall('Review'):\n",
        "  for sentence in root.findall('sentence'):\n",
        "    #for sentence in sentences.findall('sentence'):\n",
        "    sent = []\n",
        "    sent_characteristics = []\n",
        "    text = sentence.find('text').text\n",
        "    sent.append(text)\n",
        "    polarity = []\n",
        "    for opinions in sentence.findall('aspectCategories'):\n",
        "      for opinion in opinions.findall('aspectCategory'):\n",
        "        elem = [opinion.get('category'), opinion.get('polarity')]\n",
        "        polarity.append(elem)\n",
        "    sent_characteristics.append(polarity)\n",
        "    s.append(sent)\n",
        "    p.append(sent_characteristics)\n",
        "        \n",
        "  return s, p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ICKDvL6oBQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_sentences, train_adnotations = getSentences(\"./train2014.xml\")\n",
        "test_sentences, test_adnotations = getSentences(\"./test2014.xml\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10jPK5U1oRsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb741de7-a540-4834-b9cb-3d078e67bd9b"
      },
      "source": [
        "test_adnotations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['service', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None], ['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None], ['ambience', None]]],\n",
              " [[['food', None], ['price', None], ['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None], ['price', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['price', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['price', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['ambience', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['price', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None], ['price', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['ambience', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None], ['service', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['price', None], ['food', None]]],\n",
              " [[['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None]]],\n",
              " [[['service', None], ['price', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None], ['service', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None], ['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None],\n",
              "   ['food', None],\n",
              "   ['price', None],\n",
              "   ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['price', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None], ['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None], ['ambience', None]]],\n",
              " [[['service', None], ['food', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None], ['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['price', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None], ['price', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None], ['service', None], ['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['food', None], ['price', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['service', None]]],\n",
              " [[['price', None], ['ambience', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['ambience', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None], ['ambience', None], ['service', None]]],\n",
              " [[['service', None], ['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['price', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None], ['service', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['price', None], ['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['price', None]]],\n",
              " [[['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None], ['service', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['service', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None], ['price', None]]],\n",
              " [[['food', None], ['ambience', None], ['service', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None], ['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['price', None], ['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['service', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['price', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None], ['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['food', None], ['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None], ['ambience', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['price', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None], ['food', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None],\n",
              "   ['service', None],\n",
              "   ['price', None],\n",
              "   ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['food', None], ['price', None]]],\n",
              " [[['food', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None], ['anecdotes/miscellaneous', None]]],\n",
              " [[['food', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['ambience', None]]],\n",
              " [[['service', None]]],\n",
              " [[['anecdotes/miscellaneous', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['service', None]]],\n",
              " [[['food', None], ['service', None]]],\n",
              " [[['ambience', None], ['food', None]]],\n",
              " [[['food', None]]]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkKTxFFTopGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_reviews = []\n",
        "train_aspects = []\n",
        "test_reviews = []\n",
        "test_aspects = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afNifDs5osJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in train_sentences:\n",
        "  train_reviews.append(' '.join(review))\n",
        "for ta in train_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  train_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfnIbaJJoxrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for review in test_sentences:\n",
        "  test_reviews.append(' '.join(review))\n",
        "  \n",
        "for ta in test_adnotations:\n",
        "  aspect = set()\n",
        "  for adnotation_set in ta:\n",
        "    for a in adnotation_set:\n",
        "      aspect.add(a[0])\n",
        "  test_aspects.append(aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWeY7sQto6eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLabels(aspects):\n",
        "\t#print(unique_aspects)\n",
        "\t#Create train labels\n",
        "  food = []\n",
        "  service\t= []\n",
        "  miscellaneous = []\n",
        "  ambience = []\n",
        "  price = []\n",
        "\n",
        "  for aspect in aspects:\n",
        "    if 'food' in aspect:\n",
        "      food.append(1)\n",
        "    else:\n",
        "      food.append(0)\n",
        "\t\t\t\n",
        "    if 'anecdotes/miscellaneous' in aspect:\n",
        "      miscellaneous.append(1)\n",
        "    else:\n",
        "      miscellaneous.append(0)\n",
        "\t\t\t\n",
        "    if 'service' in aspect:\n",
        "      service.append(1)\n",
        "    else:\n",
        "      service.append(0)\n",
        "\n",
        "    if 'ambience' in aspect:\n",
        "      ambience.append(1)\n",
        "    else:\n",
        "      ambience.append(0)\n",
        "\t\t\t  \n",
        "    if 'price' in aspect:\n",
        "      price.append(1)\n",
        "    else:\n",
        "      price.append(0)\n",
        "\t\t\t\t\n",
        "  return food, miscellaneous ,service ,price , ambience"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4INOrmEri1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test and Train labels\n",
        "test1, test2, test3, test4, test5 = getLabels(test_aspects)\n",
        "test_labels = [test1, test2, test3, test4, test5]\n",
        "\n",
        "train1, train2, train3, train4, train5 = getLabels(train_aspects)\n",
        "train_labels = [train1, train2, train3, train4, train5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqRfuWaii_KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGrOD4UyjFr9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9cb65af1-51f3-431b-d094-2080e4bf8e95"
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FKpaYrpjJnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiOnjNaujPZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'sentence'\n",
        "LABEL_COLUMN = 'polarity'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuEyApPxjRId",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.DataFrame(list(zip(train_reviews, train5)), \n",
        "               columns =['sentence', 'polarity']) \n",
        "test = pd.DataFrame(list(zip(test_reviews, test5)), \n",
        "               columns =['sentence', 'polarity']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvpJ6d-2rAH2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZCLmrIwkcFg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zfY0ZmZkg7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ef94dedf-03a3-428b-9f13-eb97e8097b60"
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWUjTKqzkrIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d8ab881-999a-487b-fa51-b7f840fa1d00"
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 3041\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 3041\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] but the staff was so horrible to us . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] but the staff was so horrible to us . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2021 1996 3095 2001 2061 9202 2000 2149 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2021 1996 3095 2001 2061 9202 2000 2149 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] to be completely fair , the only red ##eem ##ing factor was the food , which was above average , but couldn ' t make up for all the other def ##iciencies of te ##od ##ora . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] to be completely fair , the only red ##eem ##ing factor was the food , which was above average , but couldn ' t make up for all the other def ##iciencies of te ##od ##ora . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2000 2022 3294 4189 1010 1996 2069 2417 21564 2075 5387 2001 1996 2833 1010 2029 2001 2682 2779 1010 2021 2481 1005 1056 2191 2039 2005 2035 1996 2060 13366 28227 1997 8915 7716 6525 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2000 2022 3294 4189 1010 1996 2069 2417 21564 2075 5387 2001 1996 2833 1010 2029 2001 2682 2779 1010 2021 2481 1005 1056 2191 2039 2005 2035 1996 2060 13366 28227 1997 8915 7716 6525 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the food is uniformly exceptional , with a very capable kitchen which will proudly whip up whatever you feel like eating , whether it ' s on the menu or not . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the food is uniformly exceptional , with a very capable kitchen which will proudly whip up whatever you feel like eating , whether it ' s on the menu or not . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2833 2003 27423 11813 1010 2007 1037 2200 5214 3829 2029 2097 18067 11473 2039 3649 2017 2514 2066 5983 1010 3251 2009 1005 1055 2006 1996 12183 2030 2025 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 2833 2003 27423 11813 1010 2007 1037 2200 5214 3829 2029 2097 18067 11473 2039 3649 2017 2514 2066 5983 1010 3251 2009 1005 1055 2006 1996 12183 2030 2025 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] where gabriel ##a personal ##y greet ##s you and recommends you what to eat . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] where gabriel ##a personal ##y greet ##s you and recommends you what to eat . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2073 6127 2050 3167 2100 17021 2015 2017 1998 26021 2017 2054 2000 4521 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2073 6127 2050 3167 2100 17021 2015 2017 1998 26021 2017 2054 2000 4521 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] for those that go once and don ' t enjoy it , all i can say is that they just don ' t get it . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] for those that go once and don ' t enjoy it , all i can say is that they just don ' t get it . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2005 2216 2008 2175 2320 1998 2123 1005 1056 5959 2009 1010 2035 1045 2064 2360 2003 2008 2027 2074 2123 1005 1056 2131 2009 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2005 2216 2008 2175 2320 1998 2123 1005 1056 5959 2009 1010 2035 1045 2064 2360 2003 2008 2027 2074 2123 1005 1056 2131 2009 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 800\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the bread is top notch as well . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the bread is top notch as well . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 7852 2003 2327 18624 2004 2092 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 7852 2003 2327 18624 2004 2092 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i have to say they have one of the fastest delivery times in the city . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i have to say they have one of the fastest delivery times in the city . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2031 2000 2360 2027 2031 2028 1997 1996 7915 6959 2335 1999 1996 2103 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2031 2000 2360 2027 2031 2028 1997 1996 7915 6959 2335 1999 1996 2103 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] food is always fresh and hot - ready to eat ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] food is always fresh and hot - ready to eat ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2833 2003 2467 4840 1998 2980 1011 3201 2000 4521 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2833 2003 2467 4840 1998 2980 1011 3201 2000 4521 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] did i mention that the coffee is outstanding ? [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] did i mention that the coffee is outstanding ? [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2106 1045 5254 2008 1996 4157 2003 5151 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2106 1045 5254 2008 1996 4157 2003 5151 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] certainly not the best su ##shi in new york , however , it is always fresh , and the place is very clean , sterile . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] certainly not the best su ##shi in new york , however , it is always fresh , and the place is very clean , sterile . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5121 2025 1996 2190 10514 6182 1999 2047 2259 1010 2174 1010 2009 2003 2467 4840 1010 1998 1996 2173 2003 2200 4550 1010 25403 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 5121 2025 1996 2190 10514 6182 1999 2047 2259 1010 2174 1010 2009 2003 2467 4840 1010 1998 1996 2173 2003 2200 4550 1010 25403 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42KenYE5kwIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aF3t8q6lBGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        f1_score = tf.contrib.metrics.f1_score(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        auc = tf.metrics.auc(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"f1_score\": f1_score,\n",
        "            \"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAvbnK7slJV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OvtqBoolN93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZQ89uzOlRgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "807a315b-60f6-44c3-9ab2-aa1719b32dc6"
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpjzgeq_ni\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpjzgeq_ni\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpjzgeq_ni', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdfb6a715c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpjzgeq_ni', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdfb6a715c0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghpMe2wHlV__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGFO16rDlYrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "4e208466-bd80-4844-86a6-cdedb394b4a1"
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpjzgeq_ni/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpjzgeq_ni/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5363327, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.5363327, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.576459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.576459\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.14639258, step = 100 (173.475 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.14639258, step = 100 (173.475 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.643391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.643391\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0048140865, step = 200 (155.427 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.0048140865, step = 200 (155.427 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 285 into /tmp/tmpjzgeq_ni/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 285 into /tmp/tmpjzgeq_ni/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.003011277.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.003011277.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:08:46.167680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULDpXglulbPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNbz1wgilegt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "4fc26b96-0357-4498-deca-d618d52a72b5"
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-07-07T15:01:40Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-07-07T15:01:40Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjzgeq_ni/model.ckpt-285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpjzgeq_ni/model.ckpt-285\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-07-07-15:02:05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-07-07-15:02:05\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 285: auc = 0.9177022, eval_accuracy = 0.96125, f1_score = 0.86695266, false_negatives = 17.0, false_positives = 14.0, global_step = 285, loss = 0.15127382, precision = 0.87826085, recall = 0.8559322, true_negatives = 668.0, true_positives = 101.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 285: auc = 0.9177022, eval_accuracy = 0.96125, f1_score = 0.86695266, false_negatives = 17.0, false_positives = 14.0, global_step = 285, loss = 0.15127382, precision = 0.87826085, recall = 0.8559322, true_negatives = 668.0, true_positives = 101.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 285: /tmp/tmpjzgeq_ni/model.ckpt-285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 285: /tmp/tmpjzgeq_ni/model.ckpt-285\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.9177022,\n",
              " 'eval_accuracy': 0.96125,\n",
              " 'f1_score': 0.86695266,\n",
              " 'false_negatives': 17.0,\n",
              " 'false_positives': 14.0,\n",
              " 'global_step': 285,\n",
              " 'loss': 0.15127382,\n",
              " 'precision': 0.87826085,\n",
              " 'recall': 0.8559322,\n",
              " 'true_negatives': 668.0,\n",
              " 'true_positives': 101.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ut54PUbfoG5k",
        "colab_type": "text"
      },
      "source": [
        "**END OF BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KjupCJGuIp1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "12223faf-e92a-4fca-cf67-270eafef8c98"
      },
      "source": [
        "xx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-ce3af7760f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBc-1FCbrzTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "cf0c0c4f-2207-4ad7-a667-fc0760f4ad0c"
      },
      "source": [
        "#Vectorizing data\n",
        "vectorizer = CountVectorizer(analyzer='word', lowercase=True, stop_words='english', ngram_range=(1,2))\n",
        "vectorizer.fit(train_reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmLXDkGNsR9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = vectorizer.transform(train_reviews)\n",
        "x_test = vectorizer.transform(test_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRgBQp8pp3Nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4eKR9DfuKkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E8E0hAPpyhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train[1:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoP6JovqsTJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = x_train.shape[1]\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000)\n",
        "tokenizer.fit_on_texts(train_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOQB6y_sWhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = tokenizer.texts_to_sequences(train_reviews)\n",
        "x_test = tokenizer.texts_to_sequences(test_reviews)\n",
        "vocab_size = len(tokenizer.word_index) + 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0p7KbY6qBrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_train[0:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Oyt4kSwsczJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 300\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding = 'post', maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m08x4vOHqghu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train[0:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRrmKYFTz1EF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pretrained Word Embeddings\n",
        "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
        "\tvocab_size = len(word_index) + 1\n",
        "\tembedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "\t\n",
        "\twith open(filepath, encoding='utf-8') as f:\n",
        "\t\tfor line in f:\n",
        "\t\t\tword, *vector = line.split()\n",
        "\t\t\tif word in word_index:\n",
        "\t\t\t\tidx = word_index[word]\n",
        "\t\t\t\tembedding_matrix[idx] = np.array(vector[-300:], dtype=np.float32)[:embedding_dim]\n",
        "\n",
        "\treturn embedding_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2kN8-Cr0BT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "embedding_matrix = create_embedding_matrix('./glove.840B.300d.txt', tokenizer.word_index, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq7O5SJM0EsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYSI1rjA0JFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "def getPredictions(x_train, x_test, train, test):\n",
        "\tembedding_dim = 300\n",
        "\t#early_stopping_monitor = EarlyStopping(patience=3)\n",
        "\tembedding_matrix = create_embedding_matrix('./glove.840B.300d.txt', tokenizer.word_index, embedding_dim)\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length = maxlen, trainable = True))\n",
        "\tmodel.add(layers.Conv1D(64, 3, activation = 'relu'))\n",
        "\tmodel.add(layers.GlobalMaxPool1D())\n",
        "\tmodel.add(layers.Dense(10, activation='relu'))\n",
        "\tmodel.add(layers.Dense(1, activation='sigmoid'))\n",
        "\tmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1, 'accuracy'])\n",
        "\t#model.summary()\n",
        "\n",
        "\thistory = model.fit(x_train, train, epochs = 20, verbose = 1, validation_data = (x_test, test), batch_size = 10)\n",
        "\tval = model.evaluate(x_train, train, verbose = False)\n",
        "\t#val = model.evaluate(x_test, test, verbose = False)\n",
        "\n",
        "\tpredictions = model.predict(x_test)\n",
        "\tpredictions_class = model.predict_classes(x_test)\n",
        "\t#predictions1 = model.predict(testt)\n",
        "\t#predictions11 = model.predict_classes(testt)\n",
        "\treturn predictions, predictions_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcWp9hMGskBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "83212d58-0c50-4be6-9ac6-345d396874d1"
      },
      "source": [
        "embedding_dim = 300\n",
        "from gensim.models import KeyedVectors\n",
        "word2vec_model = KeyedVectors.load_word2vec_format(os.path.join('./GoogleNews-vectors-negative300.bin.gz'), binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dCmx7ztsmAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model: \n",
        "        embedding_vector = word2vec_model[word]\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg0Yxqg-sskU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            embedding_dim,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=maxlen,\n",
        "                            trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBODTA1wtVdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        Only computes a batch-wise average of recall.\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "        Only computes a batch-wise average of precision.\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zv86gzatJ6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "def getPredictions(x_train, x_test, train, test):\n",
        "\tembedding_dim = 300\n",
        "\t#early_stopping_monitor = EarlyStopping(patience=3)\n",
        "\t#embedding_matrix = create_embedding_matrix('./glove.840B.300d.txt', tokenizer.word_index, embedding_dim)\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(embedding_layer)\n",
        "\tmodel.add(layers.Conv1D(64, 3, activation = 'relu'))\n",
        "\tmodel.add(layers.GlobalMaxPool1D())\n",
        "\tmodel.add(layers.Dense(10, activation='relu'))\n",
        "\tmodel.add(layers.Dense(1, activation='sigmoid'))\n",
        "\tmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1, 'accuracy'])\n",
        "\t#model.summary()\n",
        "\n",
        "\thistory = model.fit(x_train, train, epochs = 20, verbose = 1, validation_data = (x_test, test), batch_size = 10)\n",
        "\tval = model.evaluate(x_train, train, verbose = False)\n",
        "\t#val = model.evaluate(x_test, test, verbose = False)\n",
        "\n",
        "\tpredictions = model.predict(x_test)\n",
        "\tpredictions_class = model.predict_classes(x_test)\n",
        "\t#predictions1 = model.predict(testt)\n",
        "\t#predictions11 = model.predict_classes(testt)\n",
        "\treturn predictions, predictions_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdNDlyXutaRt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "outputId": "960eb828-925f-4bae-ed4d-27580804160b"
      },
      "source": [
        "print(\"Getting Predictions1\")\n",
        "predictions1, predictions_class1 = getPredictions(x_train, x_test, train1, test1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Predictions1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/20\n",
            "3041/3041 [==============================] - 9s 3ms/step - loss: 0.3157 - f1: 0.8228 - accuracy: 0.8800 - val_loss: 0.2259 - val_f1: 0.9072 - val_accuracy: 0.9187\n",
            "Epoch 2/20\n",
            "3041/3041 [==============================] - 3s 891us/step - loss: 0.1309 - f1: 0.9224 - accuracy: 0.9494 - val_loss: 0.2132 - val_f1: 0.9036 - val_accuracy: 0.9162\n",
            "Epoch 3/20\n",
            "3041/3041 [==============================] - 3s 880us/step - loss: 0.0493 - f1: 0.9688 - accuracy: 0.9865 - val_loss: 0.2591 - val_f1: 0.8947 - val_accuracy: 0.9100\n",
            "Epoch 4/20\n",
            "3041/3041 [==============================] - 3s 883us/step - loss: 0.0151 - f1: 0.9958 - accuracy: 0.9974 - val_loss: 0.3142 - val_f1: 0.8999 - val_accuracy: 0.9137\n",
            "Epoch 5/20\n",
            "3041/3041 [==============================] - 3s 916us/step - loss: 0.0037 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.3045 - val_f1: 0.9088 - val_accuracy: 0.9212\n",
            "Epoch 6/20\n",
            "3041/3041 [==============================] - 3s 879us/step - loss: 0.0017 - f1: 0.9967 - accuracy: 1.0000 - val_loss: 0.3208 - val_f1: 0.9088 - val_accuracy: 0.9200\n",
            "Epoch 7/20\n",
            "3041/3041 [==============================] - 3s 888us/step - loss: 9.7752e-04 - f1: 0.9934 - accuracy: 1.0000 - val_loss: 0.3334 - val_f1: 0.9091 - val_accuracy: 0.9200\n",
            "Epoch 8/20\n",
            "3041/3041 [==============================] - 3s 876us/step - loss: 6.4764e-04 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.3495 - val_f1: 0.9061 - val_accuracy: 0.9175\n",
            "Epoch 9/20\n",
            "3041/3041 [==============================] - 3s 928us/step - loss: 4.6329e-04 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.3588 - val_f1: 0.9081 - val_accuracy: 0.9187\n",
            "Epoch 10/20\n",
            "3041/3041 [==============================] - 3s 921us/step - loss: 3.4365e-04 - f1: 0.9967 - accuracy: 1.0000 - val_loss: 0.3694 - val_f1: 0.9081 - val_accuracy: 0.9187\n",
            "Epoch 11/20\n",
            "3041/3041 [==============================] - 3s 880us/step - loss: 2.5768e-04 - f1: 0.9967 - accuracy: 1.0000 - val_loss: 0.3773 - val_f1: 0.9070 - val_accuracy: 0.9175\n",
            "Epoch 12/20\n",
            "3041/3041 [==============================] - 3s 893us/step - loss: 1.9865e-04 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.3855 - val_f1: 0.9060 - val_accuracy: 0.9162\n",
            "Epoch 13/20\n",
            "3041/3041 [==============================] - 3s 898us/step - loss: 1.5491e-04 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.4034 - val_f1: 0.9085 - val_accuracy: 0.9187\n",
            "Epoch 14/20\n",
            "3041/3041 [==============================] - 3s 913us/step - loss: 1.2249e-04 - f1: 0.9967 - accuracy: 1.0000 - val_loss: 0.4114 - val_f1: 0.9085 - val_accuracy: 0.9187\n",
            "Epoch 15/20\n",
            "3041/3041 [==============================] - 3s 912us/step - loss: 9.6821e-05 - f1: 0.9967 - accuracy: 1.0000 - val_loss: 0.4130 - val_f1: 0.9060 - val_accuracy: 0.9162\n",
            "Epoch 16/20\n",
            "3041/3041 [==============================] - 3s 882us/step - loss: 7.7735e-05 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.4258 - val_f1: 0.9066 - val_accuracy: 0.9162\n",
            "Epoch 17/20\n",
            "3041/3041 [==============================] - 3s 873us/step - loss: 6.2492e-05 - f1: 0.9934 - accuracy: 1.0000 - val_loss: 0.4342 - val_f1: 0.9066 - val_accuracy: 0.9162\n",
            "Epoch 18/20\n",
            "3041/3041 [==============================] - 3s 906us/step - loss: 5.0524e-05 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.4415 - val_f1: 0.9066 - val_accuracy: 0.9162\n",
            "Epoch 19/20\n",
            "3041/3041 [==============================] - 3s 935us/step - loss: 4.1321e-05 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.4497 - val_f1: 0.9105 - val_accuracy: 0.9162\n",
            "Epoch 20/20\n",
            "3041/3041 [==============================] - 3s 877us/step - loss: 3.3695e-05 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.4588 - val_f1: 0.9116 - val_accuracy: 0.9175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2k2e_wtt4Fq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4fb3fb2e-b3d1-4759-a4dc-d8bfff804d56"
      },
      "source": [
        "print(\"Getting Predictions2\")\n",
        "predictions2, predictions_class2 = getPredictions(x_train, x_test, train2, test2)\n",
        "print(\"Getting Predictions3\")\n",
        "predictions3, predictions_class3 = getPredictions(x_train, x_test, train3, test3)\n",
        "print(\"Getting Predictions4\")\n",
        "predictions4, predictions_class4 = getPredictions(x_train, x_test, train4, test4)\n",
        "print(\"Getting Predictions5\")\n",
        "predictions5, predictions_class5 = getPredictions(x_train, x_test, train5, test5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting Predictions2\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/20\n",
            "3041/3041 [==============================] - 3s 955us/step - loss: 0.3710 - f1: 0.7311 - accuracy: 0.8356 - val_loss: 0.3526 - val_f1: 0.6671 - val_accuracy: 0.8462\n",
            "Epoch 2/20\n",
            "3041/3041 [==============================] - 3s 886us/step - loss: 0.1636 - f1: 0.8903 - accuracy: 0.9398 - val_loss: 0.3692 - val_f1: 0.6686 - val_accuracy: 0.8625\n",
            "Epoch 3/20\n",
            "3041/3041 [==============================] - 3s 925us/step - loss: 0.0483 - f1: 0.9654 - accuracy: 0.9872 - val_loss: 0.4488 - val_f1: 0.6571 - val_accuracy: 0.8512\n",
            "Epoch 4/20\n",
            "3041/3041 [==============================] - 3s 871us/step - loss: 0.0120 - f1: 0.9862 - accuracy: 0.9993 - val_loss: 0.5267 - val_f1: 0.6604 - val_accuracy: 0.8537\n",
            "Epoch 5/20\n",
            "3041/3041 [==============================] - 3s 886us/step - loss: 0.0037 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.5754 - val_f1: 0.6635 - val_accuracy: 0.8550\n",
            "Epoch 6/20\n",
            "3041/3041 [==============================] - 3s 936us/step - loss: 0.0017 - f1: 0.9934 - accuracy: 1.0000 - val_loss: 0.6110 - val_f1: 0.6628 - val_accuracy: 0.8550\n",
            "Epoch 7/20\n",
            "3041/3041 [==============================] - 3s 858us/step - loss: 8.3353e-04 - f1: 0.9934 - accuracy: 1.0000 - val_loss: 0.6432 - val_f1: 0.6715 - val_accuracy: 0.8575\n",
            "Epoch 8/20\n",
            "3041/3041 [==============================] - 3s 877us/step - loss: 5.4826e-04 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.6673 - val_f1: 0.6656 - val_accuracy: 0.8550\n",
            "Epoch 9/20\n",
            "3041/3041 [==============================] - 3s 873us/step - loss: 3.8731e-04 - f1: 0.9934 - accuracy: 1.0000 - val_loss: 0.6942 - val_f1: 0.6678 - val_accuracy: 0.8562\n",
            "Epoch 10/20\n",
            "3041/3041 [==============================] - 3s 924us/step - loss: 2.7850e-04 - f1: 0.9967 - accuracy: 1.0000 - val_loss: 0.7175 - val_f1: 0.6684 - val_accuracy: 0.8575\n",
            "Epoch 11/20\n",
            "3041/3041 [==============================] - 3s 881us/step - loss: 2.0753e-04 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.7375 - val_f1: 0.6678 - val_accuracy: 0.8562\n",
            "Epoch 12/20\n",
            "3041/3041 [==============================] - 3s 893us/step - loss: 1.5713e-04 - f1: 0.9934 - accuracy: 1.0000 - val_loss: 0.7571 - val_f1: 0.6583 - val_accuracy: 0.8512\n",
            "Epoch 13/20\n",
            "3041/3041 [==============================] - 3s 868us/step - loss: 1.2063e-04 - f1: 0.9803 - accuracy: 1.0000 - val_loss: 0.7769 - val_f1: 0.6667 - val_accuracy: 0.8562\n",
            "Epoch 14/20\n",
            "3041/3041 [==============================] - 3s 917us/step - loss: 9.3112e-05 - f1: 0.9836 - accuracy: 1.0000 - val_loss: 0.7948 - val_f1: 0.6583 - val_accuracy: 0.8512\n",
            "Epoch 15/20\n",
            "3041/3041 [==============================] - 3s 878us/step - loss: 7.2851e-05 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.8147 - val_f1: 0.6655 - val_accuracy: 0.8550\n",
            "Epoch 16/20\n",
            "3041/3041 [==============================] - 3s 876us/step - loss: 5.7802e-05 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.8326 - val_f1: 0.6589 - val_accuracy: 0.8525\n",
            "Epoch 17/20\n",
            "3041/3041 [==============================] - 3s 894us/step - loss: 4.5734e-05 - f1: 0.9836 - accuracy: 1.0000 - val_loss: 0.8491 - val_f1: 0.6589 - val_accuracy: 0.8525\n",
            "Epoch 18/20\n",
            "3041/3041 [==============================] - 3s 895us/step - loss: 3.6517e-05 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.8669 - val_f1: 0.6630 - val_accuracy: 0.8537\n",
            "Epoch 19/20\n",
            "3041/3041 [==============================] - 3s 858us/step - loss: 2.9233e-05 - f1: 0.9902 - accuracy: 1.0000 - val_loss: 0.8840 - val_f1: 0.6630 - val_accuracy: 0.8537\n",
            "Epoch 20/20\n",
            "3041/3041 [==============================] - 3s 865us/step - loss: 2.3422e-05 - f1: 0.9869 - accuracy: 1.0000 - val_loss: 0.9006 - val_f1: 0.6589 - val_accuracy: 0.8512\n",
            "Getting Predictions3\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/20\n",
            "3041/3041 [==============================] - 3s 959us/step - loss: 0.2424 - f1: 0.5524 - accuracy: 0.9092 - val_loss: 0.1176 - val_f1: 0.7730 - val_accuracy: 0.9600\n",
            "Epoch 2/20\n",
            "3041/3041 [==============================] - 3s 881us/step - loss: 0.0703 - f1: 0.8131 - accuracy: 0.9757 - val_loss: 0.1333 - val_f1: 0.7683 - val_accuracy: 0.9588\n",
            "Epoch 3/20\n",
            "3041/3041 [==============================] - 3s 910us/step - loss: 0.0187 - f1: 0.8564 - accuracy: 0.9964 - val_loss: 0.1576 - val_f1: 0.7687 - val_accuracy: 0.9600\n",
            "Epoch 4/20\n",
            "3041/3041 [==============================] - 3s 874us/step - loss: 0.0053 - f1: 0.9005 - accuracy: 0.9997 - val_loss: 0.1703 - val_f1: 0.7726 - val_accuracy: 0.9625\n",
            "Epoch 5/20\n",
            "3041/3041 [==============================] - 3s 906us/step - loss: 0.0030 - f1: 0.8944 - accuracy: 0.9997 - val_loss: 0.1832 - val_f1: 0.7708 - val_accuracy: 0.9613\n",
            "Epoch 6/20\n",
            "3041/3041 [==============================] - 3s 906us/step - loss: 0.0015 - f1: 0.8715 - accuracy: 0.9997 - val_loss: 0.1804 - val_f1: 0.7833 - val_accuracy: 0.9625\n",
            "Epoch 7/20\n",
            "3041/3041 [==============================] - 3s 961us/step - loss: 3.9087e-04 - f1: 0.8689 - accuracy: 1.0000 - val_loss: 0.1891 - val_f1: 0.7833 - val_accuracy: 0.9625\n",
            "Epoch 8/20\n",
            "3041/3041 [==============================] - 3s 917us/step - loss: 2.2281e-04 - f1: 0.8885 - accuracy: 1.0000 - val_loss: 0.1995 - val_f1: 0.7833 - val_accuracy: 0.9625\n",
            "Epoch 9/20\n",
            "3041/3041 [==============================] - 3s 932us/step - loss: 1.5234e-04 - f1: 0.8918 - accuracy: 1.0000 - val_loss: 0.2095 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 10/20\n",
            "3041/3041 [==============================] - 3s 896us/step - loss: 1.1030e-04 - f1: 0.8951 - accuracy: 1.0000 - val_loss: 0.2117 - val_f1: 0.7819 - val_accuracy: 0.9613\n",
            "Epoch 11/20\n",
            "3041/3041 [==============================] - 3s 874us/step - loss: 8.2956e-05 - f1: 0.8754 - accuracy: 1.0000 - val_loss: 0.2179 - val_f1: 0.7819 - val_accuracy: 0.9613\n",
            "Epoch 12/20\n",
            "3041/3041 [==============================] - 3s 895us/step - loss: 6.3822e-05 - f1: 0.8918 - accuracy: 1.0000 - val_loss: 0.2235 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 13/20\n",
            "3041/3041 [==============================] - 3s 886us/step - loss: 4.9782e-05 - f1: 0.8754 - accuracy: 1.0000 - val_loss: 0.2287 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 14/20\n",
            "3041/3041 [==============================] - 3s 873us/step - loss: 3.9512e-05 - f1: 0.8852 - accuracy: 1.0000 - val_loss: 0.2333 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 15/20\n",
            "3041/3041 [==============================] - 3s 894us/step - loss: 3.1582e-05 - f1: 0.9016 - accuracy: 1.0000 - val_loss: 0.2354 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 16/20\n",
            "3041/3041 [==============================] - 3s 945us/step - loss: 2.5419e-05 - f1: 0.9082 - accuracy: 1.0000 - val_loss: 0.2426 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 17/20\n",
            "3041/3041 [==============================] - 3s 869us/step - loss: 2.0565e-05 - f1: 0.8721 - accuracy: 1.0000 - val_loss: 0.2447 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 18/20\n",
            "3041/3041 [==============================] - 3s 890us/step - loss: 1.6740e-05 - f1: 0.8885 - accuracy: 1.0000 - val_loss: 0.2503 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 19/20\n",
            "3041/3041 [==============================] - 3s 885us/step - loss: 1.3691e-05 - f1: 0.8885 - accuracy: 1.0000 - val_loss: 0.2547 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Epoch 20/20\n",
            "3041/3041 [==============================] - 3s 881us/step - loss: 1.1140e-05 - f1: 0.8656 - accuracy: 1.0000 - val_loss: 0.2602 - val_f1: 0.7694 - val_accuracy: 0.9600\n",
            "Getting Predictions4\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/20\n",
            "3041/3041 [==============================] - 3s 1ms/step - loss: 0.1855 - f1: 0.2964 - accuracy: 0.9336 - val_loss: 0.0717 - val_f1: 0.5147 - val_accuracy: 0.9850\n",
            "Epoch 2/20\n",
            "3041/3041 [==============================] - 3s 900us/step - loss: 0.0574 - f1: 0.5947 - accuracy: 0.9809 - val_loss: 0.0748 - val_f1: 0.4929 - val_accuracy: 0.9762\n",
            "Epoch 3/20\n",
            "3041/3041 [==============================] - 3s 909us/step - loss: 0.0172 - f1: 0.6830 - accuracy: 0.9944 - val_loss: 0.1006 - val_f1: 0.4452 - val_accuracy: 0.9712\n",
            "Epoch 4/20\n",
            "3041/3041 [==============================] - 3s 904us/step - loss: 0.0070 - f1: 0.6868 - accuracy: 0.9984 - val_loss: 0.0850 - val_f1: 0.4819 - val_accuracy: 0.9750\n",
            "Epoch 5/20\n",
            "3041/3041 [==============================] - 3s 890us/step - loss: 0.0034 - f1: 0.6660 - accuracy: 0.9990 - val_loss: 0.0885 - val_f1: 0.4833 - val_accuracy: 0.9775\n",
            "Epoch 6/20\n",
            "3041/3041 [==============================] - 3s 889us/step - loss: 0.0011 - f1: 0.6623 - accuracy: 1.0000 - val_loss: 0.1081 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 7/20\n",
            "3041/3041 [==============================] - 3s 917us/step - loss: 4.1116e-04 - f1: 0.6393 - accuracy: 1.0000 - val_loss: 0.1046 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 8/20\n",
            "3041/3041 [==============================] - 3s 924us/step - loss: 2.5749e-04 - f1: 0.6590 - accuracy: 1.0000 - val_loss: 0.1088 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 9/20\n",
            "3041/3041 [==============================] - 3s 913us/step - loss: 1.8365e-04 - f1: 0.6754 - accuracy: 1.0000 - val_loss: 0.1143 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 10/20\n",
            "3041/3041 [==============================] - 3s 877us/step - loss: 1.3615e-04 - f1: 0.6852 - accuracy: 1.0000 - val_loss: 0.1147 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 11/20\n",
            "3041/3041 [==============================] - 3s 950us/step - loss: 1.0422e-04 - f1: 0.6754 - accuracy: 1.0000 - val_loss: 0.1224 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 12/20\n",
            "3041/3041 [==============================] - 3s 879us/step - loss: 8.1990e-05 - f1: 0.6689 - accuracy: 1.0000 - val_loss: 0.1212 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 13/20\n",
            "3041/3041 [==============================] - 3s 876us/step - loss: 6.4717e-05 - f1: 0.6721 - accuracy: 1.0000 - val_loss: 0.1229 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 14/20\n",
            "3041/3041 [==============================] - 3s 881us/step - loss: 5.1833e-05 - f1: 0.6656 - accuracy: 1.0000 - val_loss: 0.1265 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 15/20\n",
            "3041/3041 [==============================] - 3s 884us/step - loss: 4.1571e-05 - f1: 0.6393 - accuracy: 1.0000 - val_loss: 0.1296 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 16/20\n",
            "3041/3041 [==============================] - 3s 896us/step - loss: 3.3889e-05 - f1: 0.6492 - accuracy: 1.0000 - val_loss: 0.1320 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 17/20\n",
            "3041/3041 [==============================] - 3s 909us/step - loss: 2.7709e-05 - f1: 0.6984 - accuracy: 1.0000 - val_loss: 0.1334 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 18/20\n",
            "3041/3041 [==============================] - 3s 887us/step - loss: 2.2634e-05 - f1: 0.6820 - accuracy: 1.0000 - val_loss: 0.1338 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 19/20\n",
            "3041/3041 [==============================] - 3s 908us/step - loss: 1.8649e-05 - f1: 0.6721 - accuracy: 1.0000 - val_loss: 0.1372 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Epoch 20/20\n",
            "3041/3041 [==============================] - 3s 886us/step - loss: 1.5472e-05 - f1: 0.6852 - accuracy: 1.0000 - val_loss: 0.1395 - val_f1: 0.4840 - val_accuracy: 0.9775\n",
            "Getting Predictions5\n",
            "Train on 3041 samples, validate on 800 samples\n",
            "Epoch 1/20\n",
            "3041/3041 [==============================] - 3s 979us/step - loss: 0.2357 - f1: 0.3794 - accuracy: 0.9155 - val_loss: 0.1739 - val_f1: 0.5486 - val_accuracy: 0.9425\n",
            "Epoch 2/20\n",
            "3041/3041 [==============================] - 3s 877us/step - loss: 0.0728 - f1: 0.6879 - accuracy: 0.9770 - val_loss: 0.1796 - val_f1: 0.5318 - val_accuracy: 0.9413\n",
            "Epoch 3/20\n",
            "3041/3041 [==============================] - 3s 881us/step - loss: 0.0189 - f1: 0.7402 - accuracy: 0.9961 - val_loss: 0.2321 - val_f1: 0.4973 - val_accuracy: 0.9337\n",
            "Epoch 4/20\n",
            "3041/3041 [==============================] - 3s 884us/step - loss: 0.0071 - f1: 0.7727 - accuracy: 0.9990 - val_loss: 0.2251 - val_f1: 0.5531 - val_accuracy: 0.9325\n",
            "Epoch 5/20\n",
            "3041/3041 [==============================] - 3s 925us/step - loss: 0.0015 - f1: 0.7967 - accuracy: 1.0000 - val_loss: 0.2658 - val_f1: 0.5178 - val_accuracy: 0.9388\n",
            "Epoch 6/20\n",
            "3041/3041 [==============================] - 3s 880us/step - loss: 6.1783e-04 - f1: 0.7574 - accuracy: 1.0000 - val_loss: 0.2783 - val_f1: 0.5178 - val_accuracy: 0.9388\n",
            "Epoch 7/20\n",
            "3041/3041 [==============================] - 3s 906us/step - loss: 3.9636e-04 - f1: 0.7803 - accuracy: 1.0000 - val_loss: 0.2953 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 8/20\n",
            "3041/3041 [==============================] - 3s 950us/step - loss: 2.7676e-04 - f1: 0.7869 - accuracy: 1.0000 - val_loss: 0.2992 - val_f1: 0.5178 - val_accuracy: 0.9388\n",
            "Epoch 9/20\n",
            "3041/3041 [==============================] - 3s 876us/step - loss: 2.0260e-04 - f1: 0.7967 - accuracy: 1.0000 - val_loss: 0.3125 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 10/20\n",
            "3041/3041 [==============================] - 3s 974us/step - loss: 1.5357e-04 - f1: 0.7770 - accuracy: 1.0000 - val_loss: 0.3203 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 11/20\n",
            "3041/3041 [==============================] - 3s 879us/step - loss: 1.1889e-04 - f1: 0.8033 - accuracy: 1.0000 - val_loss: 0.3253 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 12/20\n",
            "3041/3041 [==============================] - 3s 874us/step - loss: 9.2797e-05 - f1: 0.7705 - accuracy: 1.0000 - val_loss: 0.3356 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 13/20\n",
            "3041/3041 [==============================] - 3s 887us/step - loss: 7.3535e-05 - f1: 0.7902 - accuracy: 1.0000 - val_loss: 0.3412 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 14/20\n",
            "3041/3041 [==============================] - 3s 873us/step - loss: 5.8766e-05 - f1: 0.7869 - accuracy: 1.0000 - val_loss: 0.3473 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 15/20\n",
            "3041/3041 [==============================] - 3s 897us/step - loss: 4.7610e-05 - f1: 0.7738 - accuracy: 1.0000 - val_loss: 0.3559 - val_f1: 0.5070 - val_accuracy: 0.9362\n",
            "Epoch 16/20\n",
            "3041/3041 [==============================] - 3s 1ms/step - loss: 3.8367e-05 - f1: 0.7672 - accuracy: 1.0000 - val_loss: 0.3612 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 17/20\n",
            "3041/3041 [==============================] - 3s 960us/step - loss: 3.1184e-05 - f1: 0.7934 - accuracy: 1.0000 - val_loss: 0.3695 - val_f1: 0.5070 - val_accuracy: 0.9362\n",
            "Epoch 18/20\n",
            "3041/3041 [==============================] - 3s 983us/step - loss: 2.5676e-05 - f1: 0.8197 - accuracy: 1.0000 - val_loss: 0.3756 - val_f1: 0.5070 - val_accuracy: 0.9362\n",
            "Epoch 19/20\n",
            "3041/3041 [==============================] - 3s 944us/step - loss: 2.1072e-05 - f1: 0.7639 - accuracy: 1.0000 - val_loss: 0.3815 - val_f1: 0.5095 - val_accuracy: 0.9375\n",
            "Epoch 20/20\n",
            "3041/3041 [==============================] - 3s 905us/step - loss: 1.7314e-05 - f1: 0.7213 - accuracy: 1.0000 - val_loss: 0.3866 - val_f1: 0.5095 - val_accuracy: 0.9375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfBKEWC_wFDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions1 = predictions1[:, 0]\n",
        "predictions_class1 = predictions_class1[:, 0]\n",
        "\n",
        "predictions2 = predictions2[:, 0]\n",
        "predictions_class2 = predictions_class2[:, 0]\n",
        "\n",
        "predictions3 = predictions3[:, 0]\n",
        "predictions_class3 = predictions_class3[:, 0]\n",
        "\n",
        "predictions4 = predictions4[:, 0]\n",
        "predictions_class4 = predictions_class4[:, 0]\n",
        "\n",
        "predictions5 = predictions5[:, 0]\n",
        "predictions_class5 = predictions_class5[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffFsTkbHwJG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFUX1hX34353",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "6485d13b-bd25-476b-d0a7-b3a722d0d8e1"
      },
      "source": [
        "print(\"Accuracy1: \", accuracy1)\n",
        "print(\"Precision1\",precision1)\n",
        "print(\"Recall1\",recall1)\n",
        "print(\"Auc1\",auc1)\n",
        "print(\"F1_score1\",f1_score1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy1:  0.9175\n",
            "Precision1 0.9559585492227979\n",
            "Recall1 0.8827751196172249\n",
            "Auc1 0.9191362509080888\n",
            "F1_score1 0.9179104477611939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAhAfwGYwL5S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e9348d6-d8ec-4d4c-b086-f7ca1ed65d82"
      },
      "source": [
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy1 = accuracy_score(test1, predictions_class1)\n",
        "accuracy2 = accuracy_score(test2, predictions_class2)\n",
        "accuracy3 = accuracy_score(test3, predictions_class3)\n",
        "accuracy4 = accuracy_score(test4, predictions_class4)\n",
        "accuracy5 = accuracy_score(test5, predictions_class5)\n",
        "final_accuracy = (accuracy1 + accuracy2 + accuracy3 + accuracy4 + accuracy5) / 5\n",
        "final_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhIXmYU7wZoW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b82f9048-4970-433e-c041-4c1668b39cd3"
      },
      "source": [
        "# precision tp / (tp + fp)\n",
        "precision1 = precision_score(test1, predictions_class1)\n",
        "precision2 = precision_score(test2, predictions_class2)\n",
        "precision3 = precision_score(test3, predictions_class3)\n",
        "precision4 = precision_score(test4, predictions_class4)\n",
        "precision5 = precision_score(test5, predictions_class5)\n",
        "final_precision_score = (precision1 + precision2 + precision3 + precision4 + precision5) / 5\n",
        "final_precision_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8993400352352132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i7aiJCewjO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96c738da-2ce1-4d91-e52b-675750d8aa7a"
      },
      "source": [
        "# recall: tp / (tp + fn)\n",
        "recall1 = recall_score(test1, predictions_class1)\n",
        "recall2 = recall_score(test2, predictions_class2)\n",
        "recall3 = recall_score(test3, predictions_class3)\n",
        "recall4 = recall_score(test4, predictions_class4)\n",
        "recall5 = recall_score(test5, predictions_class5)\n",
        "final_recall_score = (recall1 + recall2 + recall3 + recall4 + recall5) / 5\n",
        "final_recall_score "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7923315874204924"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5xvov9SwoWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f06b0bec-fce5-4d76-9076-e5fc1d32f2e4"
      },
      "source": [
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1_score1 = f1_score(test1, predictions_class1)\n",
        "f1_score2 = f1_score(test2, predictions_class2)\n",
        "f1_score3 = f1_score(test3, predictions_class3)\n",
        "f1_score4 = f1_score(test4, predictions_class4)\n",
        "f1_score5 = f1_score(test5, predictions_class5)\n",
        "final_f1_score = (f1_score1 + f1_score2 + f1_score3 + f1_score4 + f1_score5) / 5\n",
        "final_f1_score  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.841148579311892"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v5wSITuAA57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a82b5ba-67a1-4fab-cd1c-c7aafee2622a"
      },
      "source": [
        "f1_score1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9179104477611939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ln4uU8wvxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9e8f09f0-0b21-4dfc-f317-ae320903f870"
      },
      "source": [
        "# ROC AUC\n",
        "auc1 = roc_auc_score(test1, predictions_class1)\n",
        "auc2 = roc_auc_score(test2, predictions_class2)\n",
        "auc3 = roc_auc_score(test3, predictions_class3)\n",
        "auc4 = roc_auc_score(test4, predictions_class4)\n",
        "auc5 = roc_auc_score(test5, predictions_class5)\n",
        "final_auc = (auc1 + auc2 + auc3 + auc4 + auc5) / 5\n",
        "final_auc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.878677898926506"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFAYaLEUw_ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_aspects = []\n",
        "nr = len(test_sentences)\n",
        "\n",
        "for i in range(nr):\n",
        "  predicted_aspect = []\n",
        "  \n",
        "  if predictions1[i] > 0.4:\n",
        "    predicted_aspect.append('food')\n",
        "  if predictions2[i] > 0.4:\n",
        "    predicted_aspect.append('miscellaneous')\n",
        "  if predictions3[i] > 0.4:\n",
        "    predicted_aspect.append('service')\n",
        "  if predictions4[i] > 0.4:\n",
        "    predicted_aspect.append('price')\n",
        "  if predictions5[i] > 0.4:\n",
        "    predicted_aspect.append('ambience')\n",
        "    \n",
        "  predicted_aspects.append(predicted_aspect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta7Hcow9xY1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluating the system\n",
        "common_aspects = 0\n",
        "relevant_aspects = 0\n",
        "retrieved_aspects = 0\n",
        "\n",
        "for i in range(nr):\n",
        "  correct = set()\n",
        "  for aspect in test_aspects[i]:\n",
        "    correct.add(aspect)\n",
        "  \n",
        "  predicted = set()\n",
        "  for aspect in predicted_aspects[i]:\n",
        "    predicted.add(aspect)\n",
        "    \n",
        "  relevant_aspects = relevant_aspects + len(correct)\n",
        "  retrieved_aspects = retrieved_aspects + len(predicted)\n",
        "  common_aspects = common_aspects+len([aspect for aspect in predicted if aspect in correct])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kbGHNlUxaKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "84ce031c-d434-41f3-886f-75ce2eb7bda2"
      },
      "source": [
        "print(\"Common aspects: \", common_aspects)\n",
        "print(\"Retrieved aspects: \", retrieved_aspects)\n",
        "print(\"Relevant aspects: \", relevant_aspects)\n",
        "precision = common_aspects / retrieved_aspects if retrieved_aspects > 0 else 0\n",
        "recall = common_aspects / relevant_aspects\n",
        "f1_measure = 2 * precision * recall / (precision + recall)\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Recall: \", recall)\n",
        "print(\"F1: \", f1_measure)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Common aspects:  668\n",
            "Retrieved aspects:  944\n",
            "Relevant aspects:  1025\n",
            "Precision:  0.7076271186440678\n",
            "Recall:  0.6517073170731708\n",
            "F1:  0.6785170137125445\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}